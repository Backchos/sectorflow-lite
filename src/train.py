#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - Training Module
ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€

Functions:
- train_model: ëª¨ë¸ í›ˆë ¨
- evaluate_model: ëª¨ë¸ í‰ê°€
- handle_class_imbalance: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
- cross_validate: êµì°¨ ê²€ì¦
- save_model: ëª¨ë¸ ì €ì¥
- load_model: ëª¨ë¸ ë¡œë“œ
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Tuple, List, Optional
import os
import json
import yaml
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def load_config(config_path: str = "config.yaml") -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"âš ï¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return {}
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return {}

# TensorFlow/Keras
try:
    import tensorflow as tf
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
    from tensorflow.keras.utils import to_categorical
    from sklearn.utils.class_weight import compute_class_weight
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from gru import create_model_factory, create_callbacks
from dataio import prepare_ml_data

def handle_class_imbalance(y_train: np.ndarray, 
                          method: str = 'class_weight') -> Dict[str, Any]:
    """
    í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
    
    Args:
        y_train: í›ˆë ¨ ë¼ë²¨
        method: ì²˜ë¦¬ ë°©ë²• ('class_weight', 'smote', 'undersample')
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"ğŸ”§ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì¤‘ ({method})...")
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    unique_classes, counts = np.unique(y_train, return_counts=True)
    class_distribution = dict(zip(unique_classes, counts))
    
    print(f"   - í´ë˜ìŠ¤ ë¶„í¬: {class_distribution}")
    
    result = {
        'method': method,
        'original_distribution': class_distribution,
        'class_weights': None,
        'y_train_processed': y_train
    }
    
    if method == 'class_weight':
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        class_weights = compute_class_weight(
            'balanced',
            classes=unique_classes,
            y=y_train
        )
        class_weight_dict = dict(zip(unique_classes, class_weights))
        result['class_weights'] = class_weight_dict
        
        print(f"   - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weight_dict}")
    
    elif method == 'smote':
        # SMOTE ì ìš© (ì¶”í›„ êµ¬í˜„)
        print("   - SMOTEëŠ” ì¶”í›„ êµ¬í˜„ ì˜ˆì •")
        pass
    
    elif method == 'undersample':
        # ì–¸ë”ìƒ˜í”Œë§ (ì¶”í›„ êµ¬í˜„)
        print("   - ì–¸ë”ìƒ˜í”Œë§ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •")
        pass
    
    print("âœ… í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì™„ë£Œ!")
    return result

def train_model(model, 
                X_train: np.ndarray, 
                y_train: np.ndarray,
                X_valid: np.ndarray, 
                y_valid: np.ndarray,
                config: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ëª¨ë¸ í›ˆë ¨
    
    Args:
        model: í›ˆë ¨í•  ëª¨ë¸
        X_train: í›ˆë ¨ í”¼ì²˜
        y_train: í›ˆë ¨ ë¼ë²¨
        X_valid: ê²€ì¦ í”¼ì²˜
        y_valid: ê²€ì¦ ë¼ë²¨
        config: í›ˆë ¨ ì„¤ì •
        
    Returns:
        í›ˆë ¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    # ê¸°ë³¸ ì„¤ì •
    if config is None:
        config = {
            'epochs': 100,
            'batch_size': 32,
            'validation_split': 0.2,
            'patience': 15,
            'learning_rate': 0.001,
            'class_imbalance_method': 'class_weight'
        }
    
    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
    imbalance_result = handle_class_imbalance(y_train, config.get('class_imbalance_method', 'class_weight'))
    
    # ì½œë°± ìƒì„±
    callbacks = create_callbacks(
        patience=config.get('patience', 15),
        min_delta=config.get('min_delta', 0.001),
        factor=config.get('factor', 0.5),
        min_lr=config.get('min_lr', 1e-7)
    )
    
    # í›ˆë ¨ ì‹œì‘
    start_time = datetime.now()
    
    history = model.fit(
        X_train, y_train,
        validation_data=(X_valid, y_valid),
        epochs=config.get('epochs', 100),
        batch_size=config.get('batch_size', 32),
        callbacks=callbacks,
        class_weight=imbalance_result['class_weights'],
        verbose=1
    )
    
    end_time = datetime.now()
    training_time = (end_time - start_time).total_seconds()
    
    # í›ˆë ¨ ê²°ê³¼
    training_result = {
        'model': model,
        'history': history.history,
        'training_time': training_time,
        'epochs_trained': len(history.history['loss']),
        'best_epoch': np.argmin(history.history['val_loss']) + 1,
        'best_val_loss': min(history.history['val_loss']),
        'best_val_accuracy': max(history.history['val_accuracy']),
        'class_imbalance_result': imbalance_result,
        'config': config
    }
    
    print(f"âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {training_time:.1f}ì´ˆ)")
    print(f"   - í›ˆë ¨ ì—í¬í¬: {training_result['epochs_trained']}")
    print(f"   - ìµœê³  ê²€ì¦ ì •í™•ë„: {training_result['best_val_accuracy']:.4f}")
    print(f"   - ìµœì € ê²€ì¦ ì†ì‹¤: {training_result['best_val_loss']:.4f}")
    
    return training_result

def evaluate_model(model, 
                   X_test: np.ndarray, 
                   y_test: np.ndarray,
                   threshold: float = 0.5) -> Dict[str, Any]:
    """
    ëª¨ë¸ í‰ê°€
    
    Args:
        model: í‰ê°€í•  ëª¨ë¸
        X_test: í…ŒìŠ¤íŠ¸ í”¼ì²˜
        y_test: í…ŒìŠ¤íŠ¸ ë¼ë²¨
        threshold: ë¶„ë¥˜ ì„ê³„ê°’
        
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
    
    # ì˜ˆì¸¡
    y_pred_proba = model.predict(X_test, verbose=0)
    y_pred = (y_pred_proba > threshold).astype(int).flatten()
    
    # ê¸°ë³¸ ì§€í‘œ ê³„ì‚°
    accuracy = np.mean(y_test == y_pred)
    precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1) if np.sum(y_pred == 1) > 0 else 0
    recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1) if np.sum(y_test == 1) > 0 else 0
    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    # ROC AUC ê³„ì‚°
    from sklearn.metrics import roc_auc_score, roc_curve
    try:
        roc_auc = roc_auc_score(y_test, y_pred_proba)
    except ValueError:
        roc_auc = 0.0
    
    # í˜¼ë™ í–‰ë ¬
    from sklearn.metrics import confusion_matrix
    cm = confusion_matrix(y_test, y_pred)
    
    # í´ë˜ìŠ¤ë³„ ì„±ê³¼
    tn, fp, fn, tp = cm.ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    evaluation_result = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score,
        'roc_auc': roc_auc,
        'specificity': specificity,
        'sensitivity': sensitivity,
        'confusion_matrix': cm.tolist(),
        'y_true': y_test.tolist(),
        'y_pred': y_pred.tolist(),
        'y_pred_proba': y_pred_proba.flatten().tolist(),
        'threshold': threshold
    }
    
    print(f"ğŸ“Š í‰ê°€ ê²°ê³¼:")
    print(f"   - ì •í™•ë„: {accuracy:.4f}")
    print(f"   - ì •ë°€ë„: {precision:.4f}")
    print(f"   - ì¬í˜„ìœ¨: {recall:.4f}")
    print(f"   - F1 ì ìˆ˜: {f1_score:.4f}")
    print(f"   - ROC AUC: {roc_auc:.4f}")
    
    return evaluation_result

def cross_validate(model_factory_func,
                   X: np.ndarray, 
                   y: np.ndarray,
                   cv_folds: int = 5,
                   config: Dict[str, Any] = None,
                   run_id: str = None) -> Dict[str, Any]:
    """
    ì‹œê³„ì—´ êµì°¨ ê²€ì¦
    
    Args:
        model_factory_func: ëª¨ë¸ ìƒì„± í•¨ìˆ˜
        X: ì „ì²´ í”¼ì²˜
        y: ì „ì²´ ë¼ë²¨
        cv_folds: êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜
        config: ì„¤ì •
        run_id: ì‹¤í–‰ ID
        
    Returns:
        êµì°¨ ê²€ì¦ ê²°ê³¼
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ”„ {cv_folds}-Fold ì‹œê³„ì—´ êµì°¨ ê²€ì¦ ì‹œì‘...")
    
    # ì‹œê³„ì—´ êµì°¨ ê²€ì¦ ì‚¬ìš©
    from sklearn.model_selection import TimeSeriesSplit
    
    # ì„¤ì •ì—ì„œ êµì°¨ ê²€ì¦ ì˜µì…˜ ê°€ì ¸ì˜¤ê¸°
    cv_config = config.get('cv', {}) if config else {}
    use_timeseries = cv_config.get('timeseries', True)
    use_rolling = cv_config.get('rolling', True)
    
    if use_timeseries:
        cv = TimeSeriesSplit(n_splits=cv_folds)
    else:
        from sklearn.model_selection import KFold
        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
    
    cv_results = {
        'fold_scores': [],
        'mean_scores': {},
        'std_scores': {},
        'all_predictions': [],
        'all_true_labels': [],
        'cv_type': 'timeseries' if use_timeseries else 'kfold',
        'rolling': use_rolling
    }
    
    fold_scores = []
    
    for fold, (train_idx, val_idx) in enumerate(cv.split(X)):
        print(f"   ğŸ“Š Fold {fold + 1}/{cv_folds} í›ˆë ¨ ì¤‘...")
        
        # ë°ì´í„° ë¶„í• 
        X_train_fold, X_val_fold = X[train_idx], X[val_idx]
        y_train_fold, y_val_fold = y[train_idx], y[val_idx]
        
        # ëª¨ë¸ ìƒì„±
        model = model_factory_func()
        
        # í›ˆë ¨
        training_result = train_model(
            model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, config
        )
        
        # í‰ê°€
        eval_result = evaluate_model(model, X_val_fold, y_val_fold)
        
        # ê²°ê³¼ ì €ì¥
        fold_scores.append({
            'fold': fold + 1,
            'accuracy': eval_result['accuracy'],
            'precision': eval_result['precision'],
            'recall': eval_result['recall'],
            'f1_score': eval_result['f1_score'],
            'roc_auc': eval_result['roc_auc']
        })
        
        cv_results['all_predictions'].extend(eval_result['y_pred'])
        cv_results['all_true_labels'].extend(eval_result['y_true'])
    
    # í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°
    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']
    
    for metric in metrics:
        scores = [fold[metric] for fold in fold_scores]
        cv_results['mean_scores'][metric] = np.mean(scores)
        cv_results['std_scores'][metric] = np.std(scores)
    
    cv_results['fold_scores'] = fold_scores
    
    # CV ê²°ê³¼ ì €ì¥
    if run_id:
        save_cv_results(cv_results, run_id)
    
    print(f"âœ… ì‹œê³„ì—´ êµì°¨ ê²€ì¦ ì™„ë£Œ!")
    print(f"   - CV íƒ€ì…: {cv_results['cv_type']}")
    print(f"   - í‰ê·  ì •í™•ë„: {cv_results['mean_scores']['accuracy']:.4f} Â± {cv_results['std_scores']['accuracy']:.4f}")
    print(f"   - í‰ê·  F1 ì ìˆ˜: {cv_results['mean_scores']['f1_score']:.4f} Â± {cv_results['std_scores']['f1_score']:.4f}")
    print(f"   - í‰ê·  ROC AUC: {cv_results['mean_scores']['roc_auc']:.4f} Â± {cv_results['std_scores']['roc_auc']:.4f}")
    
    return cv_results

def save_cv_results(cv_results: Dict[str, Any], run_id: str) -> None:
    """CV ê²°ê³¼ ì €ì¥"""
    import json
    import os
    
    # runs ë””ë ‰í† ë¦¬ ìƒì„±
    runs_dir = f"runs/{run_id}"
    os.makedirs(runs_dir, exist_ok=True)
    
    # CV ê²°ê³¼ ì €ì¥
    cv_file = os.path.join(runs_dir, "cv_metrics.json")
    with open(cv_file, 'w', encoding='utf-8') as f:
        json.dump(cv_results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ CV ê²°ê³¼ ì €ì¥: {cv_file}")

def save_model(training_result: Dict[str, Any], 
               model_path: str,
               save_history: bool = True) -> None:
    """
    ëª¨ë¸ ì €ì¥
    
    Args:
        training_result: í›ˆë ¨ ê²°ê³¼
        model_path: ì €ì¥ ê²½ë¡œ
        save_history: í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥ ì—¬ë¶€
    """
    if not TENSORFLOW_AVAILABLE:
        print("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘... ({model_path})")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    model = training_result['model']
    model.save(model_path)
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'model_name': model.name,
        'epochs_trained': training_result['epochs_trained'],
        'best_epoch': training_result['best_epoch'],
        'best_val_loss': float(training_result['best_val_loss']),
        'best_val_accuracy': float(training_result['best_val_accuracy']),
        'training_time': training_result['training_time'],
        'config': training_result['config'],
        'class_imbalance_result': training_result['class_imbalance_result']
    }
    
    metadata_path = model_path.replace('.h5', '_metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥
    if save_history:
        history_path = model_path.replace('.h5', '_history.json')
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(training_result['history'], f, indent=2, ensure_ascii=False)
    
    print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")

def load_model(model_path: str) -> Dict[str, Any]:
    """
    ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ
        
    Returns:
        ë¡œë“œëœ ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„°
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘... ({model_path})")
    
    # ëª¨ë¸ ë¡œë“œ
    model = tf.keras.models.load_model(model_path)
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata_path = model_path.replace('.h5', '_metadata.json')
    metadata = {}
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    
    # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ë¡œë“œ
    history_path = model_path.replace('.h5', '_history.json')
    history = {}
    if os.path.exists(history_path):
        with open(history_path, 'r', encoding='utf-8') as f:
            history = json.load(f)
    
    result = {
        'model': model,
        'metadata': metadata,
        'history': history
    }
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return result

def train_all_models(processed_data: Dict[str, Any],
                     model_types: List[str] = ['gru', 'lstm', 'attention'],
                     config: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ëª¨ë“  ëª¨ë¸ í›ˆë ¨
    
    Args:
        processed_data: ì²˜ë¦¬ëœ ë°ì´í„°
        model_types: í›ˆë ¨í•  ëª¨ë¸ íƒ€ì…ë“¤
        config: í›ˆë ¨ ì„¤ì •
        
    Returns:
        ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ê²°ê³¼
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸš€ ëª¨ë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    all_results = {}
    
    for symbol, data in processed_data.items():
        print(f"\nğŸ“Š {symbol} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        X_train = data['X_train']
        y_train = data['y_train']
        X_valid = data['X_valid']
        y_valid = data['y_valid']
        X_test = data['X_test']
        y_test = data['y_test']
        input_shape = X_train.shape[1:]
        
        symbol_results = {}
        
        for model_type in model_types:
            try:
                print(f"   ğŸ”§ {model_type.upper()} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
                
                # ëª¨ë¸ ìƒì„±
                model = create_model_factory(model_type, input_shape)
                
                # í›ˆë ¨
                training_result = train_model(
                    model, X_train, y_train, X_valid, y_valid, config
                )
                
                # í‰ê°€
                eval_result = evaluate_model(model, X_test, y_test)
                
                symbol_results[model_type] = {
                    'training_result': training_result,
                    'evaluation_result': eval_result,
                    'model': model
                }
                
                print(f"   âœ… {model_type.upper()} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
                
            except Exception as e:
                print(f"   âŒ {model_type.upper()} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
                continue
        
        if symbol_results:
            all_results[symbol] = symbol_results
            print(f"   âœ… {symbol}: {len(symbol_results)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        else:
            print(f"   âŒ {symbol}: ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
    
    print(f"\nâœ… ì´ {len(all_results)}ê°œ ì¢…ëª© ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return all_results

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SectorFlow Lite - Training Module í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if not TENSORFLOW_AVAILABLE:
        print("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # ì„¤ì •
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-12-31',
        'lookback': 30,
        'feature_cols': ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'],
        'scale_method': 'standard'
    }
    
    training_config = {
        'epochs': 50,
        'batch_size': 32,
        'patience': 10,
        'learning_rate': 0.001,
        'class_imbalance_method': 'class_weight'
    }
    
    symbols = ['005930', '000660']  # í…ŒìŠ¤íŠ¸ìš© 2ê°œ ì¢…ëª©
    
    # ë°ì´í„° ì¤€ë¹„
    processed_data = prepare_ml_data(symbols, config)
    
    # ëª¨ë“  ëª¨ë¸ í›ˆë ¨
    all_results = train_all_models(
        processed_data, 
        model_types=['gru', 'lstm'], 
        config=training_config
    )
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š í›ˆë ¨ ê²°ê³¼ ìš”ì•½:")
    for symbol, results in all_results.items():
        print(f"\n{symbol}:")
        for model_type, result in results.items():
            eval_result = result['evaluation_result']
            print(f"   {model_type.upper()}:")
            print(f"     - ì •í™•ë„: {eval_result['accuracy']:.4f}")
            print(f"     - F1 ì ìˆ˜: {eval_result['f1_score']:.4f}")
            print(f"     - ROC AUC: {eval_result['roc_auc']:.4f}")
    
    print("\nâœ… Training Module í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return all_results

if __name__ == "__main__":
    results = main()
