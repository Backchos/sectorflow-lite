#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - Baseline Models Module
Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ (Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä, XGBoost) Íµ¨ÌòÑ

Functions:
- train_logistic_regression: Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä Î™®Îç∏ ÌõàÎ†®
- train_xgboost: XGBoost Î™®Îç∏ ÌõàÎ†®
- evaluate_model: Î™®Îç∏ ÌèâÍ∞Ä
- compare_models: Î™®Îç∏ ÏÑ±Í≥º ÎπÑÍµê
- generate_baseline_report: Î≤†Ïù¥Ïä§ÎùºÏù∏ Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.model_selection import cross_val_score, StratifiedKFold
import warnings
warnings.filterwarnings('ignore')

# XGBoostÍ∞Ä ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏßÄ ÏïäÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú try-exceptÎ°ú Ï≤òÎ¶¨
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("‚ö†Ô∏è XGBoostÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. pip install xgboostÎ°ú ÏÑ§ÏπòÌïòÏÑ∏Ïöî.")

def train_logistic_regression(X_train: np.ndarray, 
                             y_train: np.ndarray,
                             X_valid: np.ndarray, 
                             y_valid: np.ndarray,
                             **kwargs) -> Dict[str, Any]:
    """
    Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä Î™®Îç∏ ÌõàÎ†®
    
    Args:
        X_train: ÌõàÎ†® ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_train: ÌõàÎ†® ÎùºÎ≤®
        X_valid: Í≤ÄÏ¶ù ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_valid: Í≤ÄÏ¶ù ÎùºÎ≤®
        **kwargs: Ï∂îÍ∞Ä ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
        
    Returns:
        ÌõàÎ†®Îêú Î™®Îç∏Í≥º Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    print("üîß Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...")
    
    # 3D Î∞∞Ïó¥ÏùÑ 2DÎ°ú Î≥ÄÌôò (ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î•º ÌèâÎ©¥Ìôî)
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # Î™®Îç∏ ÏÉùÏÑ±
    model = LogisticRegression(
        random_state=42,
        max_iter=1000,
        **kwargs
    )
    
    # Î™®Îç∏ ÌõàÎ†®
    model.fit(X_train_2d, y_train)
    
    # ÏòàÏ∏°
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # ÌèâÍ∞Ä
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    results = {
        'model': model,
        'model_name': 'Logistic Regression',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': None,  # Î°úÏßÄÏä§Ìã± ÌöåÍ∑ÄÎäî ÌäπÏÑ± Ï§ëÏöîÎèÑÍ∞Ä Ï†úÌïúÏ†Å
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("‚úÖ Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!")
    return results

def train_xgboost(X_train: np.ndarray, 
                  y_train: np.ndarray,
                  X_valid: np.ndarray, 
                  y_valid: np.ndarray,
                  **kwargs) -> Dict[str, Any]:
    """
    XGBoost Î™®Îç∏ ÌõàÎ†®
    
    Args:
        X_train: ÌõàÎ†® ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_train: ÌõàÎ†® ÎùºÎ≤®
        X_valid: Í≤ÄÏ¶ù ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_valid: Í≤ÄÏ¶ù ÎùºÎ≤®
        **kwargs: Ï∂îÍ∞Ä ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
        
    Returns:
        ÌõàÎ†®Îêú Î™®Îç∏Í≥º Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    if not XGBOOST_AVAILABLE:
        raise ImportError("XGBoostÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. pip install xgboostÎ°ú ÏÑ§ÏπòÌïòÏÑ∏Ïöî.")
    
    print("üîß XGBoost Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...")
    
    # 3D Î∞∞Ïó¥ÏùÑ 2DÎ°ú Î≥ÄÌôò
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # Í∏∞Î≥∏ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
    default_params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'random_state': 42,
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8
    }
    
    # ÏÇ¨Ïö©Ïûê ÌååÎùºÎØ∏ÌÑ∞Î°ú ÏóÖÎç∞Ïù¥Ìä∏
    default_params.update(kwargs)
    
    # Î™®Îç∏ ÏÉùÏÑ±
    model = xgb.XGBClassifier(**default_params)
    
    # Î™®Îç∏ ÌõàÎ†®
    model.fit(
        X_train_2d, y_train,
        eval_set=[(X_valid_2d, y_valid)],
        early_stopping_rounds=10,
        verbose=False
    )
    
    # ÏòàÏ∏°
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # ÌèâÍ∞Ä
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    # ÌäπÏÑ± Ï§ëÏöîÎèÑ
    feature_importance = model.feature_importances_
    
    results = {
        'model': model,
        'model_name': 'XGBoost',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': feature_importance,
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("‚úÖ XGBoost Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!")
    return results

def train_random_forest(X_train: np.ndarray, 
                       y_train: np.ndarray,
                       X_valid: np.ndarray, 
                       y_valid: np.ndarray,
                       **kwargs) -> Dict[str, Any]:
    """
    ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏ Î™®Îç∏ ÌõàÎ†® (XGBoost ÎåÄÏïà)
    
    Args:
        X_train: ÌõàÎ†® ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_train: ÌõàÎ†® ÎùºÎ≤®
        X_valid: Í≤ÄÏ¶ù ÌîºÏ≤ò (3D Î∞∞Ïó¥)
        y_valid: Í≤ÄÏ¶ù ÎùºÎ≤®
        **kwargs: Ï∂îÍ∞Ä ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
        
    Returns:
        ÌõàÎ†®Îêú Î™®Îç∏Í≥º Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    print("üîß ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏ Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...")
    
    # 3D Î∞∞Ïó¥ÏùÑ 2DÎ°ú Î≥ÄÌôò
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # Í∏∞Î≥∏ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
    default_params = {
        'n_estimators': 100,
        'max_depth': 10,
        'random_state': 42,
        'n_jobs': -1
    }
    
    # ÏÇ¨Ïö©Ïûê ÌååÎùºÎØ∏ÌÑ∞Î°ú ÏóÖÎç∞Ïù¥Ìä∏
    default_params.update(kwargs)
    
    # Î™®Îç∏ ÏÉùÏÑ±
    model = RandomForestClassifier(**default_params)
    
    # Î™®Îç∏ ÌõàÎ†®
    model.fit(X_train_2d, y_train)
    
    # ÏòàÏ∏°
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # ÌèâÍ∞Ä
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    # ÌäπÏÑ± Ï§ëÏöîÎèÑ
    feature_importance = model.feature_importances_
    
    results = {
        'model': model,
        'model_name': 'Random Forest',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': feature_importance,
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("‚úÖ ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏ Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!")
    return results

def evaluate_model(y_true: np.ndarray, 
                   y_pred: np.ndarray, 
                   y_proba: np.ndarray, 
                   dataset_name: str) -> Dict[str, Any]:
    """
    Î™®Îç∏ ÌèâÍ∞Ä
    
    Args:
        y_true: Ïã§Ï†ú ÎùºÎ≤®
        y_pred: ÏòàÏ∏° ÎùºÎ≤®
        y_proba: ÏòàÏ∏° ÌôïÎ•†
        dataset_name: Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥Î¶Ñ
        
    Returns:
        ÌèâÍ∞Ä ÏßÄÌëú ÎîïÏÖîÎÑàÎ¶¨
    """
    # Í∏∞Î≥∏ ÏßÄÌëú
    accuracy = np.mean(y_true == y_pred)
    
    # Î∂ÑÎ•ò Î¶¨Ìè¨Ìä∏
    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
    
    # ÌòºÎèô ÌñâÎ†¨
    cm = confusion_matrix(y_true, y_pred)
    
    # ROC AUC
    try:
        roc_auc = roc_auc_score(y_true, y_proba)
    except ValueError:
        roc_auc = 0.0
    
    # Ï†ïÎ∞ÄÎèÑ, Ïû¨ÌòÑÏú®, F1
    precision = report['1']['precision'] if '1' in report else 0.0
    recall = report['1']['recall'] if '1' in report else 0.0
    f1 = report['1']['f1-score'] if '1' in report else 0.0
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm.tolist(),
        'classification_report': report
    }
    
    print(f"üìä {dataset_name} ÏÑ±Í≥º:")
    print(f"   - Ï†ïÌôïÎèÑ: {accuracy:.3f}")
    print(f"   - Ï†ïÎ∞ÄÎèÑ: {precision:.3f}")
    print(f"   - Ïû¨ÌòÑÏú®: {recall:.3f}")
    print(f"   - F1 Ï†êÏàò: {f1:.3f}")
    print(f"   - ROC AUC: {roc_auc:.3f}")
    
    return metrics

def compare_models(model_results: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    Î™®Îç∏ ÏÑ±Í≥º ÎπÑÍµê
    
    Args:
        model_results: Î™®Îç∏ Í≤∞Í≥º Î¶¨Ïä§Ìä∏
        
    Returns:
        ÎπÑÍµê Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
    """
    comparison_data = []
    
    for result in model_results:
        model_name = result['model_name']
        valid_metrics = result['valid_metrics']
        
        comparison_data.append({
            'Model': model_name,
            'Accuracy': valid_metrics['accuracy'],
            'Precision': valid_metrics['precision'],
            'Recall': valid_metrics['recall'],
            'F1 Score': valid_metrics['f1_score'],
            'ROC AUC': valid_metrics['roc_auc']
        })
    
    df_comparison = pd.DataFrame(comparison_data)
    df_comparison = df_comparison.sort_values('ROC AUC', ascending=False)
    
    return df_comparison

def generate_baseline_report(model_results: List[Dict[str, Any]], 
                           comparison_df: pd.DataFrame) -> str:
    """
    Î≤†Ïù¥Ïä§ÎùºÏù∏ Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
    
    Args:
        model_results: Î™®Îç∏ Í≤∞Í≥º Î¶¨Ïä§Ìä∏
        comparison_df: Î™®Îç∏ ÎπÑÍµê Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
        
    Returns:
        Î¶¨Ìè¨Ìä∏ Î¨∏ÏûêÏó¥
    """
    report = f"""
üìä SectorFlow Lite - Baseline Models Î¶¨Ìè¨Ìä∏
{'='*60}

üèÜ Î™®Îç∏ ÏÑ±Í≥º ÎπÑÍµê
{comparison_df.to_string(index=False)}

üìà ÏÉÅÏÑ∏ ÏÑ±Í≥º Î∂ÑÏÑù
"""
    
    for result in model_results:
        model_name = result['model_name']
        train_metrics = result['train_metrics']
        valid_metrics = result['valid_metrics']
        
        report += f"""
{model_name}
{'-'*30}
ÌõàÎ†® Îç∞Ïù¥ÌÑ∞:
  - Ï†ïÌôïÎèÑ: {train_metrics['accuracy']:.3f}
  - Ï†ïÎ∞ÄÎèÑ: {train_metrics['precision']:.3f}
  - Ïû¨ÌòÑÏú®: {train_metrics['recall']:.3f}
  - F1 Ï†êÏàò: {train_metrics['f1_score']:.3f}
  - ROC AUC: {train_metrics['roc_auc']:.3f}

Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞:
  - Ï†ïÌôïÎèÑ: {valid_metrics['accuracy']:.3f}
  - Ï†ïÎ∞ÄÎèÑ: {valid_metrics['precision']:.3f}
  - Ïû¨ÌòÑÏú®: {valid_metrics['recall']:.3f}
  - F1 Ï†êÏàò: {valid_metrics['f1_score']:.3f}
  - ROC AUC: {valid_metrics['roc_auc']:.3f}
"""
    
    # ÏµúÍ≥† ÏÑ±Í≥º Î™®Îç∏
    best_model = comparison_df.iloc[0]
    report += f"""

ü•á ÏµúÍ≥† ÏÑ±Í≥º Î™®Îç∏: {best_model['Model']}
   - ROC AUC: {best_model['ROC AUC']:.3f}
   - F1 Score: {best_model['F1 Score']:.3f}

{'='*60}
"""
    
    return report

def train_all_baselines(processed_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Î™®Îì† Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ ÌõàÎ†®
    
    Args:
        processed_data: Ï≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨
        
    Returns:
        Î™®Îì† Î™®Îç∏ Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    print("üöÄ Î™®Îì† Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...")
    
    all_results = {}
    
    for symbol, data in processed_data.items():
        print(f"\nüìä {symbol} Î™®Îç∏ ÌõàÎ†® Ï§ë...")
        
        X_train = data['X_train']
        y_train = data['y_train']
        X_valid = data['X_valid']
        y_valid = data['y_valid']
        
        symbol_results = []
        
        # 1. Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä
        try:
            lr_result = train_logistic_regression(X_train, y_train, X_valid, y_valid)
            symbol_results.append(lr_result)
        except Exception as e:
            print(f"   ‚ùå Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä Ïã§Ìå®: {e}")
        
        # 2. ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏
        try:
            rf_result = train_random_forest(X_train, y_train, X_valid, y_valid)
            symbol_results.append(rf_result)
        except Exception as e:
            print(f"   ‚ùå ÎûúÎç§ Ìè¨Î†àÏä§Ìä∏ Ïã§Ìå®: {e}")
        
        # 3. XGBoost (ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Í≤ΩÏö∞)
        if XGBOOST_AVAILABLE:
            try:
                xgb_result = train_xgboost(X_train, y_train, X_valid, y_valid)
                symbol_results.append(xgb_result)
            except Exception as e:
                print(f"   ‚ùå XGBoost Ïã§Ìå®: {e}")
        
        if symbol_results:
            # Î™®Îç∏ ÎπÑÍµê
            comparison_df = compare_models(symbol_results)
            
            all_results[symbol] = {
                'models': symbol_results,
                'comparison': comparison_df,
                'best_model': symbol_results[0]  # ROC AUC Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨Îêú Ï≤´ Î≤àÏß∏
            }
            
            print(f"   ‚úÖ {symbol}: {len(symbol_results)}Í∞ú Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å")
        else:
            print(f"   ‚ùå {symbol}: Î™®Îì† Î™®Îç∏ ÌõàÎ†® Ïã§Ìå®")
    
    print(f"\n‚úÖ Ï¥ù {len(all_results)}Í∞ú Ï¢ÖÎ™© Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!")
    return all_results

def main():
    """ÌÖåÏä§Ìä∏Ïö© Î©îÏù∏ Ìï®Ïàò"""
    print("üöÄ SectorFlow Lite - Baseline Models Module ÌÖåÏä§Ìä∏")
    print("=" * 60)
    
    # dataio.pyÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Í∞ÑÎã®Ìïú ÌÖåÏä§Ìä∏Ïö©)
    from dataio import prepare_ml_data
    
    # ÏÑ§Ï†ï
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-12-31',
        'lookback': 30,
        'feature_cols': ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'],
        'scale_method': 'standard'
    }
    
    symbols = ['005930', '000660']  # ÌÖåÏä§Ìä∏Ïö© 2Í∞ú Ï¢ÖÎ™©
    
    # Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
    processed_data = prepare_ml_data(symbols, config)
    
    # Î™®Îì† Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ ÌõàÎ†®
    all_results = train_all_baselines(processed_data)
    
    # Ï†ÑÏ≤¥ Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
    print("\nüìä Ï†ÑÏ≤¥ Î™®Îç∏ ÏÑ±Í≥º ÏöîÏïΩ:")
    for symbol, results in all_results.items():
        print(f"\n{symbol}:")
        print(results['comparison'].to_string(index=False))
    
    print("\n‚úÖ Baseline Models Module ÌÖåÏä§Ìä∏ ÏôÑÎ£å!")
    return all_results

if __name__ == "__main__":
    results = main()
