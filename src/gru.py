#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - GRU/LSTM Models Module
ë”¥ëŸ¬ë‹ ëª¨ë¸ (GRU, LSTM) êµ¬í˜„

Functions:
- create_gru_model: GRU ëª¨ë¸ ìƒì„±
- create_lstm_model: LSTM ëª¨ë¸ ìƒì„±
- create_attention_model: Attention ë©”ì»¤ë‹ˆì¦˜ í¬í•¨ ëª¨ë¸
- compile_model: ëª¨ë¸ ì»´íŒŒì¼
- get_model_summary: ëª¨ë¸ ìš”ì•½ ì •ë³´
"""

import numpy as np
from typing import Dict, Any, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# TensorFlow/Kerasê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-exceptë¡œ ì²˜ë¦¬
try:
    import tensorflow as tf
    from tensorflow.keras.models import Model, Sequential
    from tensorflow.keras.layers import (
        GRU, LSTM, Dense, Dropout, BatchNormalization, 
        Input, Attention, MultiHeadAttention, LayerNormalization,
        GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate
    )
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
    from tensorflow.keras.utils import plot_model
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install tensorflowë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

def create_gru_model(input_shape: Tuple[int, int],
                     hidden_sizes: list = [64, 32],
                     dropout_rate: float = 0.2,
                     recurrent_dropout: float = 0.2,
                     use_batch_norm: bool = True,
                     use_attention: bool = False) -> Model:
    """
    GRU ëª¨ë¸ ìƒì„±
    
    Args:
        input_shape: ì…ë ¥ í˜•íƒœ (timesteps, features)
        hidden_sizes: ì€ë‹‰ì¸µ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        recurrent_dropout: ìˆœí™˜ ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        use_batch_norm: ë°°ì¹˜ ì •ê·œí™” ì‚¬ìš© ì—¬ë¶€
        use_attention: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        ì»´íŒŒì¼ëœ GRU ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”§ GRU ëª¨ë¸ ìƒì„± ì¤‘...")
    
    model = Sequential()
    
    # ì…ë ¥ì¸µ
    model.add(Input(shape=input_shape))
    
    # GRU ë ˆì´ì–´ë“¤
    for i, hidden_size in enumerate(hidden_sizes):
        return_sequences = i < len(hidden_sizes) - 1 or use_attention
        
        model.add(GRU(
            hidden_size,
            return_sequences=return_sequences,
            dropout=dropout_rate,
            recurrent_dropout=recurrent_dropout,
            name=f'gru_{i+1}'
        ))
        
        if use_batch_norm:
            model.add(BatchNormalization(name=f'batch_norm_{i+1}'))
    
    # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (ì„ íƒì‚¬í•­)
    if use_attention:
        model.add(Attention(name='attention'))
    
    # ë“œë¡­ì•„ì›ƒ
    model.add(Dropout(dropout_rate, name='dropout_final'))
    
    # ì¶œë ¥ì¸µ
    model.add(Dense(1, activation='sigmoid', name='output'))
    
    print("âœ… GRU ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return model

def create_lstm_model(input_shape: Tuple[int, int],
                      hidden_sizes: list = [64, 32],
                      dropout_rate: float = 0.2,
                      recurrent_dropout: float = 0.2,
                      use_batch_norm: bool = True,
                      use_attention: bool = False) -> Model:
    """
    LSTM ëª¨ë¸ ìƒì„±
    
    Args:
        input_shape: ì…ë ¥ í˜•íƒœ (timesteps, features)
        hidden_sizes: ì€ë‹‰ì¸µ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        recurrent_dropout: ìˆœí™˜ ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        use_batch_norm: ë°°ì¹˜ ì •ê·œí™” ì‚¬ìš© ì—¬ë¶€
        use_attention: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        ì»´íŒŒì¼ëœ LSTM ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”§ LSTM ëª¨ë¸ ìƒì„± ì¤‘...")
    
    model = Sequential()
    
    # ì…ë ¥ì¸µ
    model.add(Input(shape=input_shape))
    
    # LSTM ë ˆì´ì–´ë“¤
    for i, hidden_size in enumerate(hidden_sizes):
        return_sequences = i < len(hidden_sizes) - 1 or use_attention
        
        model.add(LSTM(
            hidden_size,
            return_sequences=return_sequences,
            dropout=dropout_rate,
            recurrent_dropout=recurrent_dropout,
            name=f'lstm_{i+1}'
        ))
        
        if use_batch_norm:
            model.add(BatchNormalization(name=f'batch_norm_{i+1}'))
    
    # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (ì„ íƒì‚¬í•­)
    if use_attention:
        model.add(Attention(name='attention'))
    
    # ë“œë¡­ì•„ì›ƒ
    model.add(Dropout(dropout_rate, name='dropout_final'))
    
    # ì¶œë ¥ì¸µ
    model.add(Dense(1, activation='sigmoid', name='output'))
    
    print("âœ… LSTM ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return model

def create_attention_model(input_shape: Tuple[int, int],
                          hidden_sizes: list = [64, 32],
                          dropout_rate: float = 0.2,
                          num_heads: int = 4) -> Model:
    """
    Multi-Head Attention ëª¨ë¸ ìƒì„±
    
    Args:
        input_shape: ì…ë ¥ í˜•íƒœ (timesteps, features)
        hidden_sizes: ì€ë‹‰ì¸µ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        num_heads: ì–´í…ì…˜ í—¤ë“œ ìˆ˜
        
    Returns:
        ì»´íŒŒì¼ëœ Attention ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”§ Multi-Head Attention ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # ì…ë ¥
    inputs = Input(shape=input_shape, name='input')
    
    # ì„ë² ë”© ë ˆì´ì–´ (ì„ íƒì‚¬í•­)
    x = Dense(hidden_sizes[0], activation='relu', name='embedding')(inputs)
    x = LayerNormalization(name='layer_norm_1')(x)
    
    # Multi-Head Attention
    attention_output = MultiHeadAttention(
        num_heads=num_heads,
        key_dim=hidden_sizes[0] // num_heads,
        name='multi_head_attention'
    )(x, x)
    
    # ì”ì°¨ ì—°ê²° ë° ì •ê·œí™”
    x = Concatenate(name='concat')([x, attention_output])
    x = LayerNormalization(name='layer_norm_2')(x)
    
    # ì¶”ê°€ Dense ë ˆì´ì–´ë“¤
    for i, hidden_size in enumerate(hidden_sizes[1:], 1):
        x = Dense(hidden_size, activation='relu', name=f'dense_{i}')(x)
        x = Dropout(dropout_rate, name=f'dropout_{i}')(x)
        x = BatchNormalization(name=f'batch_norm_{i}')(x)
    
    # Global pooling
    x = GlobalAveragePooling1D(name='global_avg_pool')(x)
    
    # ì¶œë ¥ì¸µ
    outputs = Dense(1, activation='sigmoid', name='output')(x)
    
    model = Model(inputs=inputs, outputs=outputs, name='attention_model')
    
    print("âœ… Multi-Head Attention ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return model

def create_hybrid_model(input_shape: Tuple[int, int],
                        gru_hidden_sizes: list = [64, 32],
                        lstm_hidden_sizes: list = [64, 32],
                        dropout_rate: float = 0.2) -> Model:
    """
    GRU + LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìƒì„±
    
    Args:
        input_shape: ì…ë ¥ í˜•íƒœ (timesteps, features)
        gru_hidden_sizes: GRU ì€ë‹‰ì¸µ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        lstm_hidden_sizes: LSTM ì€ë‹‰ì¸µ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        dropout_rate: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
        
    Returns:
        ì»´íŒŒì¼ëœ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”§ GRU + LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # ì…ë ¥
    inputs = Input(shape=input_shape, name='input')
    
    # GRU ë¸Œëœì¹˜
    gru_branch = inputs
    for i, hidden_size in enumerate(gru_hidden_sizes):
        gru_branch = GRU(
            hidden_size,
            return_sequences=True,
            dropout=dropout_rate,
            name=f'gru_{i+1}'
        )(gru_branch)
        gru_branch = BatchNormalization(name=f'gru_batch_norm_{i+1}')(gru_branch)
    
    # LSTM ë¸Œëœì¹˜
    lstm_branch = inputs
    for i, hidden_size in enumerate(lstm_hidden_sizes):
        lstm_branch = LSTM(
            hidden_size,
            return_sequences=True,
            dropout=dropout_rate,
            name=f'lstm_{i+1}'
        )(lstm_branch)
        lstm_branch = BatchNormalization(name=f'lstm_batch_norm_{i+1}')(lstm_branch)
    
    # ë¸Œëœì¹˜ ê²°í•©
    combined = Concatenate(name='concat_branches')([gru_branch, lstm_branch])
    
    # ì¶”ê°€ ì²˜ë¦¬
    combined = Dense(64, activation='relu', name='dense_combined')(combined)
    combined = Dropout(dropout_rate, name='dropout_combined')(combined)
    combined = BatchNormalization(name='batch_norm_combined')(combined)
    
    # Global pooling
    combined = GlobalAveragePooling1D(name='global_avg_pool')(combined)
    
    # ì¶œë ¥ì¸µ
    outputs = Dense(1, activation='sigmoid', name='output')(combined)
    
    model = Model(inputs=inputs, outputs=outputs, name='hybrid_model')
    
    print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return model

def compile_model(model: Model,
                  learning_rate: float = 0.001,
                  optimizer: str = 'adam',
                  loss: str = 'binary_crossentropy',
                  metrics: list = None) -> Model:
    """
    ëª¨ë¸ ì»´íŒŒì¼
    
    Args:
        model: ì»´íŒŒì¼í•  ëª¨ë¸
        learning_rate: í•™ìŠµë¥ 
        optimizer: ì˜µí‹°ë§ˆì´ì €
        loss: ì†ì‹¤ í•¨ìˆ˜
        metrics: í‰ê°€ ì§€í‘œ
        
    Returns:
        ì»´íŒŒì¼ëœ ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if metrics is None:
        metrics = ['accuracy', 'precision', 'recall']
    
    # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    if optimizer.lower() == 'adam':
        opt = Adam(learning_rate=learning_rate)
    else:
        opt = optimizer
    
    # ëª¨ë¸ ì»´íŒŒì¼
    model.compile(
        optimizer=opt,
        loss=loss,
        metrics=metrics
    )
    
    print(f"âœ… ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ (í•™ìŠµë¥ : {learning_rate})")
    return model

def get_model_summary(model: Model) -> str:
    """
    ëª¨ë¸ ìš”ì•½ ì •ë³´ ìƒì„±
    
    Args:
        model: ëª¨ë¸
        
    Returns:
        ëª¨ë¸ ìš”ì•½ ë¬¸ìì—´
    """
    if not TENSORFLOW_AVAILABLE:
        return "TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ëª¨ë¸ êµ¬ì¡° ìš”ì•½
    summary_lines = []
    model.summary(print_fn=lambda x: summary_lines.append(x))
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = model.count_params()
    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
    non_trainable_params = total_params - trainable_params
    
    summary = "\n".join(summary_lines)
    summary += f"\n\nì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}"
    summary += f"\ní›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {trainable_params:,}"
    summary += f"\ní›ˆë ¨ ë¶ˆê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {non_trainable_params:,}"
    
    return summary

def create_callbacks(patience: int = 10,
                    min_delta: float = 0.001,
                    factor: float = 0.5,
                    min_lr: float = 1e-7,
                    save_path: str = None) -> list:
    """
    í›ˆë ¨ ì½œë°± ìƒì„±
    
    Args:
        patience: ì¡°ê¸° ì¢…ë£Œ patience
        min_delta: ìµœì†Œ ê°œì„ ëŸ‰
        factor: í•™ìŠµë¥  ê°ì†Œ ë¹„ìœ¨
        min_lr: ìµœì†Œ í•™ìŠµë¥ 
        save_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        
    Returns:
        ì½œë°± ë¦¬ìŠ¤íŠ¸
    """
    if not TENSORFLOW_AVAILABLE:
        return []
    
    callbacks = []
    
    # ì¡°ê¸° ì¢…ë£Œ
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=patience,
        min_delta=min_delta,
        restore_best_weights=True,
        verbose=1
    )
    callbacks.append(early_stopping)
    
    # í•™ìŠµë¥  ê°ì†Œ
    lr_scheduler = ReduceLROnPlateau(
        monitor='val_loss',
        factor=factor,
        patience=patience//2,
        min_lr=min_lr,
        verbose=1
    )
    callbacks.append(lr_scheduler)
    
    # ëª¨ë¸ ì €ì¥ (ê²½ë¡œê°€ ì œê³µëœ ê²½ìš°)
    if save_path:
        model_checkpoint = ModelCheckpoint(
            filepath=save_path,
            monitor='val_loss',
            save_best_only=True,
            save_weights_only=False,
            verbose=1
        )
        callbacks.append(model_checkpoint)
    
    return callbacks

def create_model_factory(model_type: str = 'gru',
                        input_shape: Tuple[int, int] = (30, 7),
                        **kwargs) -> Model:
    """
    ëª¨ë¸ íŒ©í† ë¦¬ í•¨ìˆ˜
    
    Args:
        model_type: ëª¨ë¸ íƒ€ì… ('gru', 'lstm', 'attention', 'hybrid')
        input_shape: ì…ë ¥ í˜•íƒœ
        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
    Returns:
        ìƒì„±ëœ ëª¨ë¸
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    model_type = model_type.lower()
    
    if model_type == 'gru':
        model = create_gru_model(input_shape, **kwargs)
    elif model_type == 'lstm':
        model = create_lstm_model(input_shape, **kwargs)
    elif model_type == 'attention':
        model = create_attention_model(input_shape, **kwargs)
    elif model_type == 'hybrid':
        model = create_hybrid_model(input_shape, **kwargs)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
    
    # ëª¨ë¸ ì»´íŒŒì¼
    model = compile_model(model, **kwargs)
    
    return model

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SectorFlow Lite - GRU/LSTM Models Module í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if not TENSORFLOW_AVAILABLE:
        print("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # í…ŒìŠ¤íŠ¸ìš© ì…ë ¥ í˜•íƒœ
    input_shape = (30, 7)  # 30ì¼, 7ê°œ í”¼ì²˜
    
    # ë‹¤ì–‘í•œ ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸
    models = {}
    
    # 1. GRU ëª¨ë¸
    try:
        gru_model = create_model_factory('gru', input_shape, hidden_sizes=[64, 32])
        models['GRU'] = gru_model
        print("âœ… GRU ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ GRU ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # 2. LSTM ëª¨ë¸
    try:
        lstm_model = create_model_factory('lstm', input_shape, hidden_sizes=[64, 32])
        models['LSTM'] = lstm_model
        print("âœ… LSTM ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ LSTM ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # 3. Attention ëª¨ë¸
    try:
        attention_model = create_model_factory('attention', input_shape, hidden_sizes=[64, 32])
        models['Attention'] = attention_model
        print("âœ… Attention ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ Attention ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # 4. í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
    try:
        hybrid_model = create_model_factory('hybrid', input_shape)
        models['Hybrid'] = hybrid_model
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
    for name, model in models.items():
        print(f"\nğŸ“Š {name} ëª¨ë¸ ìš”ì•½:")
        print(get_model_summary(model))
    
    print(f"\nâœ… ì´ {len(models)}ê°œ ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return models

if __name__ == "__main__":
    models = main()
