#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - Data I/O Module
ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë° ì „ì²˜ë¦¬ ëª¨ë“ˆ

Functions:
- load_data: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬
- create_labels: ë¼ë²¨ ìƒì„± (ìµì¼ ì¢…ê°€ ìƒìŠ¹ ì—¬ë¶€)
- create_windows: ì‹œê³„ì—´ ìœˆë„ìš° ìƒì„±
- split_data: ë°ì´í„° ë¶„í•  (train/valid/test)
- scale_data: ë°ì´í„° ìŠ¤ì¼€ì¼ë§
- prepare_ml_data: ë¨¸ì‹ ëŸ¬ë‹ìš© ë°ì´í„° ì¤€ë¹„
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List, Optional
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

def load_data(symbols: List[str], 
              start_date: str, 
              end_date: str,
              data_path: str = "data/raw") -> Dict[str, pd.DataFrame]:
    """
    ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬
    
    Args:
        symbols: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        data_path: ë°ì´í„° ê²½ë¡œ
        
    Returns:
        ì¢…ëª©ë³„ ë°ì´í„°í”„ë ˆì„ ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì‹œì‘...")
    
    data_dict = {}
    
    for symbol in symbols:
        try:
            # ì‹¤ì œ ë°ì´í„° ë¡œë“œ (í˜„ì¬ëŠ” ìƒ˜í”Œ ë°ì´í„° ìƒì„±)
            df = create_sample_data(symbol, start_date, end_date)
            
            # ê¸°ë³¸ ì „ì²˜ë¦¬
            df = preprocess_data(df)
            
            data_dict[symbol] = df
            print(f"   âœ… {symbol}: {len(df)}ì¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ {symbol}: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - {e}")
            continue
    
    print(f"âœ… ì´ {len(data_dict)}ê°œ ì¢…ëª© ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    return data_dict

def create_sample_data(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)
    
    Args:
        symbol: ì¢…ëª© ì½”ë“œ
        start_date: ì‹œì‘ ë‚ ì§œ
        end_date: ì¢…ë£Œ ë‚ ì§œ
        
    Returns:
        OHLCV ë°ì´í„°í”„ë ˆì„
    """
    # ë‚ ì§œ ë²”ìœ„ ìƒì„±
    dates = pd.date_range(start=start_date, end=end_date, freq='D')
    dates = dates[dates.weekday < 5]  # ì£¼ë§ ì œì™¸
    
    # ê°€ê²© ë°ì´í„° ìƒì„± (ëœë¤ ì›Œí¬)
    np.random.seed(hash(symbol) % 2**32)  # ì¢…ëª©ë³„ë¡œ ë‹¤ë¥¸ ì‹œë“œ
    
    initial_price = 50000 + (hash(symbol) % 100000)  # ì¢…ëª©ë³„ ì´ˆê¸° ê°€ê²©
    prices = [initial_price]
    
    for _ in range(len(dates) - 1):
        daily_return = np.random.normal(0, 0.02)  # 2% ì¼ì¼ ë³€ë™ì„±
        new_price = prices[-1] * (1 + daily_return)
        prices.append(max(new_price, 1000))  # ìµœì†Œ ê°€ê²© 1000ì›
    
    # OHLCV ë°ì´í„° ìƒì„±
    df = pd.DataFrame({
        'date': dates,
        'open': prices,
        'high': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
        'low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
        'close': prices,
        'volume': np.random.randint(100000, 10000000, len(dates))
    })
    
    # High, Low ì¡°ì •
    df['high'] = np.maximum(df['high'], df['close'])
    df['low'] = np.minimum(df['low'], df['close'])
    
    return df

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê¸°ë³¸ ë°ì´í„° ì „ì²˜ë¦¬
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # ë‚ ì§œ ì •ë ¬
    df = df.sort_values('date').reset_index(drop=True)
    
    # ê±°ë˜ëŒ€ê¸ˆ ê³„ì‚°
    df['trading_value'] = df['close'] * df['volume']
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    df['returns'] = df['close'].pct_change()
    
    # ì´ë™í‰ê·  ê³„ì‚°
    df['ma_5'] = df['close'].rolling(window=5).mean()
    df['ma_20'] = df['close'].rolling(window=20).mean()
    df['ma_60'] = df['close'].rolling(window=60).mean()
    
    # ë³€ë™ì„± ê³„ì‚°
    df['volatility'] = df['returns'].rolling(window=20).std()
    
    # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
    df['volume_ma_20'] = df['volume'].rolling(window=20).mean()
    
    return df

def create_labels(df: pd.DataFrame, 
                  target_col: str = 'close',
                  horizon: int = 1,
                  threshold: float = 0.0) -> pd.DataFrame:
    """
    ë¼ë²¨ ìƒì„± (ìµì¼ ì¢…ê°€ ìƒìŠ¹ ì—¬ë¶€)
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        target_col: íƒ€ê²Ÿ ì»¬ëŸ¼ (ê¸°ë³¸: close)
        horizon: ì˜ˆì¸¡ ê¸°ê°„ (ê¸°ë³¸: 1ì¼)
        threshold: ìƒìŠ¹ ì„ê³„ê°’ (ê¸°ë³¸: 0.0 = 0% ì´ìƒ)
        
    Returns:
        ë¼ë²¨ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df = df.copy()
    
    # ë¯¸ë˜ ê°€ê²© ê³„ì‚°
    future_price = df[target_col].shift(-horizon)
    current_price = df[target_col]
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = (future_price - current_price) / current_price
    
    # ë¼ë²¨ ìƒì„± (1: ìƒìŠ¹, 0: í•˜ë½)
    df['label'] = (returns > threshold).astype(int)
    df['future_return'] = returns
    df['future_price'] = future_price
    
    # ë§ˆì§€ë§‰ horizonì¼ì€ ë¼ë²¨ì´ ì—†ìŒ
    df.loc[df.index[-horizon:], 'label'] = np.nan
    df.loc[df.index[-horizon:], 'future_return'] = np.nan
    df.loc[df.index[-horizon:], 'future_price'] = np.nan
    
    return df

def create_windows(df: pd.DataFrame, 
                   lookback: int = 30,
                   feature_cols: List[str] = None) -> Tuple[np.ndarray, np.ndarray]:
    """
    ì‹œê³„ì—´ ìœˆë„ìš° ìƒì„±
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        lookback: ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸: 30ì¼)
        feature_cols: ì‚¬ìš©í•  í”¼ì²˜ ì»¬ëŸ¼ë“¤
        
    Returns:
        (X, y) - í”¼ì²˜ì™€ ë¼ë²¨ ë°°ì—´
    """
    if feature_cols is None:
        feature_cols = ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility']
    
    # ìœ íš¨í•œ í”¼ì²˜ ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_cols = [col for col in feature_cols if col in df.columns]
    
    if not available_cols:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„° ì •ë¦¬
    df_clean = df[available_cols + ['label']].dropna()
    
    if len(df_clean) < lookback + 1:
        raise ValueError(f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {lookback + 1}ê°œ í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    X, y = [], []
    
    for i in range(lookback, len(df_clean)):
        # í”¼ì²˜ ìœˆë„ìš°
        window = df_clean[available_cols].iloc[i-lookback:i].values
        X.append(window)
        
        # ë¼ë²¨
        label = df_clean['label'].iloc[i]
        y.append(label)
    
    return np.array(X), np.array(y)

def split_data(X: np.ndarray, 
               y: np.ndarray,
               train_ratio: float = 0.7,
               valid_ratio: float = 0.15,
               test_ratio: float = 0.15,
               random_state: int = 42) -> Tuple[np.ndarray, ...]:
    """
    ë°ì´í„° ë¶„í•  (train/valid/test)
    
    Args:
        X: í”¼ì²˜ ë°°ì—´
        y: ë¼ë²¨ ë°°ì—´
        train_ratio: í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨
        valid_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        test_ratio: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        random_state: ëœë¤ ì‹œë“œ
        
    Returns:
        (X_train, X_valid, X_test, y_train, y_valid, y_test)
    """
    # ë¹„ìœ¨ ê²€ì¦
    total_ratio = train_ratio + valid_ratio + test_ratio
    if abs(total_ratio - 1.0) > 1e-6:
        raise ValueError("ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ì‹œê³„ì—´ ë°ì´í„°ì´ë¯€ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë¶„í• 
    n_samples = len(X)
    train_end = int(n_samples * train_ratio)
    valid_end = int(n_samples * (train_ratio + valid_ratio))
    
    X_train = X[:train_end]
    y_train = y[:train_end]
    
    X_valid = X[train_end:valid_end]
    y_valid = y[train_end:valid_end]
    
    X_test = X[valid_end:]
    y_test = y[valid_end:]
    
    print(f"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
    print(f"   - í›ˆë ¨: {len(X_train)}ê°œ ({len(X_train)/n_samples:.1%})")
    print(f"   - ê²€ì¦: {len(X_valid)}ê°œ ({len(X_valid)/n_samples:.1%})")
    print(f"   - í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ ({len(X_test)/n_samples:.1%})")
    
    return X_train, X_valid, X_test, y_train, y_valid, y_test

def scale_data(X_train: np.ndarray, 
               X_valid: np.ndarray, 
               X_test: np.ndarray,
               method: str = 'standard') -> Tuple[np.ndarray, ...]:
    """
    ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    
    Args:
        X_train: í›ˆë ¨ í”¼ì²˜
        X_valid: ê²€ì¦ í”¼ì²˜
        X_test: í…ŒìŠ¤íŠ¸ í”¼ì²˜
        method: ìŠ¤ì¼€ì¼ë§ ë°©ë²• ('standard' ë˜ëŠ” 'minmax')
        
    Returns:
        ìŠ¤ì¼€ì¼ë§ëœ í”¼ì²˜ë“¤
    """
    print(f"ğŸ”§ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì‹œì‘ ({method})...")
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ
    if method == 'standard':
        scaler = StandardScaler()
    elif method == 'minmax':
        scaler = MinMaxScaler()
    else:
        raise ValueError("methodëŠ” 'standard' ë˜ëŠ” 'minmax'ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    # 3D ë°°ì—´ì„ 2Dë¡œ ë³€í™˜í•˜ì—¬ ìŠ¤ì¼€ì¼ë§
    original_shape = X_train.shape
    X_train_2d = X_train.reshape(-1, X_train.shape[-1])
    X_valid_2d = X_valid.reshape(-1, X_valid.shape[-1])
    X_test_2d = X_test.reshape(-1, X_test.shape[-1])
    
    # í›ˆë ¨ ë°ì´í„°ë¡œ ìŠ¤ì¼€ì¼ëŸ¬ í”¼íŒ…
    scaler.fit(X_train_2d)
    
    # ëª¨ë“  ë°ì´í„° ë³€í™˜
    X_train_scaled = scaler.transform(X_train_2d).reshape(original_shape)
    X_valid_scaled = scaler.transform(X_valid_2d).reshape(X_valid.shape)
    X_test_scaled = scaler.transform(X_test_2d).reshape(X_test.shape)
    
    print("âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ!")
    
    return X_train_scaled, X_valid_scaled, X_test_scaled, scaler

def prepare_ml_data(symbols: List[str],
                    config: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¨¸ì‹ ëŸ¬ë‹ìš© ë°ì´í„° ì¤€ë¹„ (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    
    Args:
        symbols: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì¤€ë¹„ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸš€ ë¨¸ì‹ ëŸ¬ë‹ìš© ë°ì´í„° ì¤€ë¹„ ì‹œì‘...")
    
    # ì„¤ì •ê°’ ì¶”ì¶œ
    start_date = config.get('start_date', '2024-01-01')
    end_date = config.get('end_date', '2024-12-31')
    lookback = config.get('lookback', 30)
    feature_cols = config.get('feature_cols', ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'])
    scale_method = config.get('scale_method', 'standard')
    
    # 1. ë°ì´í„° ë¡œë“œ
    data_dict = load_data(symbols, start_date, end_date)
    
    if not data_dict:
        raise ValueError("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ê° ì¢…ëª©ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
    processed_data = {}
    
    for symbol, df in data_dict.items():
        print(f"\nğŸ“Š {symbol} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # ë¼ë²¨ ìƒì„±
        df_labeled = create_labels(df, threshold=0.0)
        
        # ìœˆë„ìš° ìƒì„±
        try:
            X, y = create_windows(df_labeled, lookback=lookback, feature_cols=feature_cols)
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(
                X, y, 
                train_ratio=0.7, 
                valid_ratio=0.15, 
                test_ratio=0.15
            )
            
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            X_train_scaled, X_valid_scaled, X_test_scaled, scaler = scale_data(
                X_train, X_valid, X_test, method=scale_method
            )
            
            processed_data[symbol] = {
                'X_train': X_train_scaled,
                'X_valid': X_valid_scaled,
                'X_test': X_test_scaled,
                'y_train': y_train,
                'y_valid': y_valid,
                'y_test': y_test,
                'scaler': scaler,
                'feature_cols': feature_cols,
                'lookback': lookback,
                'original_df': df_labeled
            }
            
            print(f"   âœ… {symbol}: {len(X)}ê°œ ìœˆë„ìš° ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ {symbol}: ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")
            continue
    
    print(f"\nâœ… ì´ {len(processed_data)}ê°œ ì¢…ëª© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
    
    return processed_data

def get_data_summary(processed_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
    
    Args:
        processed_data: ì²˜ë¦¬ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ë°ì´í„° ìš”ì•½ ë”•ì…”ë„ˆë¦¬
    """
    summary = {
        'total_symbols': len(processed_data),
        'symbols': list(processed_data.keys()),
        'data_info': {}
    }
    
    for symbol, data in processed_data.items():
        summary['data_info'][symbol] = {
            'train_samples': len(data['X_train']),
            'valid_samples': len(data['X_valid']),
            'test_samples': len(data['X_test']),
            'feature_shape': data['X_train'].shape[1:],
            'positive_ratio': np.mean(data['y_train']),
            'feature_cols': data['feature_cols']
        }
    
    return summary

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SectorFlow Lite - Data I/O Module í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì„¤ì •
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-12-31',
        'lookback': 30,
        'feature_cols': ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'],
        'scale_method': 'standard'
    }
    
    symbols = ['005930', '000660', '035420']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ë„¤ì´ë²„
    
    # ë°ì´í„° ì¤€ë¹„
    processed_data = prepare_ml_data(symbols, config)
    
    # ìš”ì•½ ì •ë³´
    summary = get_data_summary(processed_data)
    
    print("\nğŸ“‹ ë°ì´í„° ìš”ì•½:")
    for symbol, info in summary['data_info'].items():
        print(f"\n{symbol}:")
        print(f"   - í›ˆë ¨: {info['train_samples']}ê°œ")
        print(f"   - ê²€ì¦: {info['valid_samples']}ê°œ")
        print(f"   - í…ŒìŠ¤íŠ¸: {info['test_samples']}ê°œ")
        print(f"   - í”¼ì²˜ í˜•íƒœ: {info['feature_shape']}")
        print(f"   - ì–‘ì„± ë¹„ìœ¨: {info['positive_ratio']:.2%}")
    
    print("\nâœ… Data I/O Module í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return processed_data

if __name__ == "__main__":
    data = main()
