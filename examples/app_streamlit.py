"""
SectorFlow Lite Streamlit Dashboard
í•œêµ­ ì£¼ì‹ ì‹œì¥ AI íˆ¬ì ì „ëµ ë°±í…ŒìŠ¤íŒ… ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import pandas as pd
import numpy as np
import json
import os
import glob
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import base64
from pathlib import Path

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="SectorFlow Lite Dashboard",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
SERVER_PORT = os.getenv("SERVER_PORT", "3000")
SERVER_ADDR = os.getenv("SERVER_ADDR", "0.0.0.0")

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
@st.cache_data
def load_json_file(file_path):
    """JSON íŒŒì¼ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {str(e)}")
        return None

@st.cache_data
def load_csv_file(file_path):
    """CSV íŒŒì¼ ë¡œë“œ"""
    try:
        return pd.read_csv(file_path)
    except Exception as e:
        st.error(f"CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {str(e)}")
        return None

def get_available_runs():
    """runs/ ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ê²°ê³¼ë“¤ ê°€ì ¸ì˜¤ê¸°"""
    runs_dir = Path("runs")
    if not runs_dir.exists():
        return []
    
    run_dirs = []
    for item in runs_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            run_dirs.append(item.name)
    
    # ìµœê·¼ ìˆœìœ¼ë¡œ ì •ë ¬
    run_dirs.sort(reverse=True)
    return run_dirs[:10]  # ìµœê·¼ 10ê°œë§Œ

def get_csv_download_link(df, filename):
    """CSV ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">ğŸ”½ CSV ë‹¤ìš´ë¡œë“œ</a>'
    return href

# ë©”ì¸ ì•±
def main():
    st.title("ğŸ“ˆ SectorFlow Lite Dashboard")
    st.markdown("í•œêµ­ ì£¼ì‹ ì‹œì¥ AI íˆ¬ì ì „ëµ ë°±í…ŒìŠ¤íŒ… ëŒ€ì‹œë³´ë“œ")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # Run ì„ íƒ
        available_runs = get_available_runs()
        if not available_runs:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € main.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        selected_run = st.selectbox(
            "ğŸ“ Run ì„ íƒ",
            available_runs,
            help="ë¶„ì„í•  ì‹¤í–‰ ê²°ê³¼ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        st.divider()
        
        # ë‚ ì§œ ë²”ìœ„
        st.subheader("ğŸ“… ë‚ ì§œ í•„í„°")
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("ì‹œì‘ì¼", value=datetime.now() - timedelta(days=30))
        with col2:
            end_date = st.date_input("ì¢…ë£Œì¼", value=datetime.now())
        
        # í‹°ì»¤ ë‹¤ì¤‘ì„ íƒ
        st.subheader("ğŸ·ï¸ ì¢…ëª© í•„í„°")
        # ê¸°ë³¸ í‹°ì»¤ë“¤ (config.yamlì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì§€ë§Œ í•˜ë“œì½”ë”©)
        default_tickers = ["005930", "000660", "035420", "005380", "006400"]
        selected_tickers = st.multiselect(
            "ì¢…ëª© ì„ íƒ",
            default_tickers,
            default=default_tickers,
            help="ë¶„ì„í•  ì¢…ëª©ë“¤ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        st.divider()
        
        # ì „ëµ í† ê¸€
        st.subheader("ğŸ¯ ì „ëµ ì„¤ì •")
        strategy_mode = st.selectbox(
            "ì „ëµ ëª¨ë“œ",
            ["ëª¨ë¸ ê¸°ë°˜(í™•ë¥ )", "ë£° ê¸°ë°˜", "ë‘˜ ë‹¤"],
            help="ì‚¬ìš©í•  ì „ëµì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # ì„ê³„ê°’ ìŠ¬ë¼ì´ë”
        threshold = st.slider(
            "ì„ê³„ê°’",
            min_value=0.0,
            max_value=1.0,
            value=0.55,
            step=0.05,
            help="ëª¨ë¸ ì‹ í˜¸ í•„í„°ë§ ì„ê³„ê°’"
        )
        
        st.divider()
        
        # ë„ì›€ë§
        st.subheader("ğŸ’¡ ë„ì›€ë§")
        st.info("""
        **ì‚¬ìš©ë²•:**
        1. Run ì„ íƒ í›„ ë‚ ì§œ/ì¢…ëª© í•„í„° ì„¤ì •
        2. ì „ëµ ëª¨ë“œì™€ ì„ê³„ê°’ ì¡°ì •
        3. ê° íƒ­ì—ì„œ ê²°ê³¼ í™•ì¸
        
        **í•„ìš” íŒŒì¼:**
        - signals_model.csv (ëª¨ë¸ ì‹ í˜¸)
        - trades.csv (ê±°ë˜ ë‚´ì—­)
        - equity_curve.csv (ìë³¸ ê³¡ì„ )
        - cv_metrics.json (êµì°¨ê²€ì¦ ê²°ê³¼)
        - backtest_summary.json (ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½)
        """)
    
    # ìƒë‹¨ KPI
    st.header("ğŸ“Š í•µì‹¬ ì§€í‘œ")
    
    # ì„ íƒëœ Run ì •ë³´ ë¡œë“œ
    run_path = Path("runs") / selected_run
    
    # KPI ê³„ì‚°
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“ ì„ íƒëœ Run", selected_run)
    
    with col2:
        cv_metrics_path = run_path / "cv_metrics.json"
        if cv_metrics_path.exists():
            cv_metrics = load_json_file(cv_metrics_path)
            if cv_metrics and 'auc_mean' in cv_metrics:
                st.metric("ğŸ¯ CV AUC (í‰ê· )", f"{cv_metrics['auc_mean']:.3f}")
            else:
                st.metric("ğŸ¯ CV AUC (í‰ê· )", "N/A")
        else:
            st.metric("ğŸ¯ CV AUC (í‰ê· )", "íŒŒì¼ ì—†ìŒ")
    
    with col3:
        backtest_summary_path = run_path / "backtest_summary.json"
        if backtest_summary_path.exists():
            backtest_summary = load_json_file(backtest_summary_path)
            if backtest_summary and 'sharpe_ratio' in backtest_summary:
                st.metric("ğŸ“ˆ Best Sharpe", f"{backtest_summary['sharpe_ratio']:.3f}")
            else:
                st.metric("ğŸ“ˆ Best Sharpe", "N/A")
        else:
            st.metric("ğŸ“ˆ Best Sharpe", "íŒŒì¼ ì—†ìŒ")
    
    st.divider()
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“‹ ê°œìš”", "ğŸ“Š ì°¨íŠ¸", "ğŸ“¡ ì‹ í˜¸", "ğŸ’° íŠ¸ë ˆì´ë“œ", "ğŸ” í´ëŸ¬ìŠ¤í„°ë§", "ğŸ“„ ë¦¬í¬íŠ¸"
    ])
    
    # 1. ê°œìš” íƒ­
    with tab1:
        st.subheader("ğŸ“‹ ì‹¤í–‰ ê²°ê³¼ ê°œìš”")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ êµì°¨ê²€ì¦ ê²°ê³¼")
            if cv_metrics_path.exists():
                cv_metrics = load_json_file(cv_metrics_path)
                if cv_metrics:
                    st.json(cv_metrics)
                else:
                    st.warning("êµì°¨ê²€ì¦ ê²°ê³¼ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("cv_metrics.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.subheader("ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½")
            if backtest_summary_path.exists():
                backtest_summary = load_json_file(backtest_summary_path)
                if backtest_summary:
                    st.json(backtest_summary)
                else:
                    st.warning("ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("backtest_summary.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ì°¨íŠ¸ íƒ­
    with tab2:
        st.subheader("ğŸ“Š ì‹œê°í™” ì°¨íŠ¸")
        
        # Equity Curve
        st.subheader("ğŸ“ˆ ìë³¸ ê³¡ì„ ")
        equity_curve_path = run_path / "equity_curve.csv"
        equity_curve_png = run_path / "equity_curve.png"
        
        if equity_curve_path.exists():
            equity_df = load_csv_file(equity_curve_path)
            if equity_df is not None:
                # ë‚ ì§œ í•„í„° ì ìš©
                if 'date' in equity_df.columns:
                    equity_df['date'] = pd.to_datetime(equity_df['date'])
                    mask = (equity_df['date'] >= pd.to_datetime(start_date)) & (equity_df['date'] <= pd.to_datetime(end_date))
                    equity_df = equity_df[mask]
                
                # Plotly ì°¨íŠ¸
                fig = px.line(equity_df, x='date', y='equity', title='ìë³¸ ê³¡ì„ ')
                fig.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="ìë³¸")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.error("ìë³¸ ê³¡ì„  ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif equity_curve_png.exists():
            st.image(str(equity_curve_png), caption="ìë³¸ ê³¡ì„  ì°¨íŠ¸")
        else:
            st.warning("ìë³¸ ê³¡ì„  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # Daily Returns
        st.subheader("ğŸ“Š ì¼ì¼ ìˆ˜ìµë¥ ")
        daily_returns_path = run_path / "daily_returns.csv"
        
        if daily_returns_path.exists():
            returns_df = load_csv_file(daily_returns_path)
            if returns_df is not None:
                # ë‚ ì§œ í•„í„° ì ìš©
                if 'date' in returns_df.columns:
                    returns_df['date'] = pd.to_datetime(returns_df['date'])
                    mask = (returns_df['date'] >= pd.to_datetime(start_date)) & (returns_df['date'] <= pd.to_datetime(end_date))
                    returns_df = returns_df[mask]
                
                # ë°” ì°¨íŠ¸
                fig = px.bar(returns_df, x='date', y='returns', title='ì¼ì¼ ìˆ˜ìµë¥ ')
                fig.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="ìˆ˜ìµë¥ ")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.error("ì¼ì¼ ìˆ˜ìµë¥  ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì¼ì¼ ìˆ˜ìµë¥  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì „ëµ ë¹„êµ (ì„ê³„ê°’ ì ìš©)
        st.subheader("ğŸ¯ ì „ëµ ë¹„êµ")
        st.info(f"í˜„ì¬ ì„¤ì •: {strategy_mode}, ì„ê³„ê°’: {threshold}")
        
        # ëª¨ë¸ vs ë£° ê¸°ë°˜ ë¹„êµ ì°¨íŠ¸ (ì˜ˆì‹œ)
        if strategy_mode == "ë‘˜ ë‹¤":
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ¤– ëª¨ë¸ ê¸°ë°˜")
                st.info("ëª¨ë¸ ê¸°ë°˜ ì „ëµ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            with col2:
                st.subheader("ğŸ“ ë£° ê¸°ë°˜")
                st.info("ë£° ê¸°ë°˜ ì „ëµ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
    
    # 3. ì‹ í˜¸ íƒ­
    with tab3:
        st.subheader("ğŸ“¡ ì‹ í˜¸ ë¶„ì„")
        
        # ëª¨ë¸ ì‹ í˜¸
        signals_model_path = run_path / "signals_model.csv"
        signals_rule_path = run_path / "signals_rule.csv"
        
        if strategy_mode in ["ëª¨ë¸ ê¸°ë°˜(í™•ë¥ )", "ë‘˜ ë‹¤"]:
            st.subheader("ğŸ¤– ëª¨ë¸ ì‹ í˜¸")
            if signals_model_path.exists():
                signals_df = load_csv_file(signals_model_path)
                if signals_df is not None:
                    # ë‚ ì§œ/í‹°ì»¤ í•„í„° ì ìš©
                    if 'date' in signals_df.columns:
                        signals_df['date'] = pd.to_datetime(signals_df['date'])
                        mask = (signals_df['date'] >= pd.to_datetime(start_date)) & (signals_df['date'] <= pd.to_datetime(end_date))
                        signals_df = signals_df[mask]
                    
                    if 'ticker' in signals_df.columns and selected_tickers:
                        signals_df = signals_df[signals_df['ticker'].isin(selected_tickers)]
                    
                    # ì„ê³„ê°’ í•„í„° ì ìš©
                    if 'probability' in signals_df.columns:
                        signals_df = signals_df[signals_df['probability'] >= threshold]
                    
                    # ì •ë ¬ ë° í‘œì‹œ
                    signals_df = signals_df.sort_values(['date', 'ticker'], ascending=[False, True])
                    
                    st.dataframe(signals_df, use_container_width=True)
                    
                    # CSV ë‹¤ìš´ë¡œë“œ
                    if st.button("ğŸ”½ ëª¨ë¸ ì‹ í˜¸ CSV ë‹¤ìš´ë¡œë“œ"):
                        csv_link = get_csv_download_link(signals_df, f"signals_model_{selected_run}.csv")
                        st.markdown(csv_link, unsafe_allow_html=True)
                else:
                    st.error("ëª¨ë¸ ì‹ í˜¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("signals_model.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if strategy_mode in ["ë£° ê¸°ë°˜", "ë‘˜ ë‹¤"]:
            st.subheader("ğŸ“ ë£° ê¸°ë°˜ ì‹ í˜¸")
            if signals_rule_path.exists():
                signals_rule_df = load_csv_file(signals_rule_path)
                if signals_rule_df is not None:
                    # ë‚ ì§œ/í‹°ì»¤ í•„í„° ì ìš©
                    if 'date' in signals_rule_df.columns:
                        signals_rule_df['date'] = pd.to_datetime(signals_rule_df['date'])
                        mask = (signals_rule_df['date'] >= pd.to_datetime(start_date)) & (signals_rule_df['date'] <= pd.to_datetime(end_date))
                        signals_rule_df = signals_rule_df[mask]
                    
                    if 'ticker' in signals_rule_df.columns and selected_tickers:
                        signals_rule_df = signals_rule_df[signals_rule_df['ticker'].isin(selected_tickers)]
                    
                    # ì •ë ¬ ë° í‘œì‹œ
                    signals_rule_df = signals_rule_df.sort_values(['date', 'ticker'], ascending=[False, True])
                    
                    st.dataframe(signals_rule_df, use_container_width=True)
                    
                    # CSV ë‹¤ìš´ë¡œë“œ
                    if st.button("ğŸ”½ ë£° ì‹ í˜¸ CSV ë‹¤ìš´ë¡œë“œ"):
                        csv_link = get_csv_download_link(signals_rule_df, f"signals_rule_{selected_run}.csv")
                        st.markdown(csv_link, unsafe_allow_html=True)
                else:
                    st.error("ë£° ê¸°ë°˜ ì‹ í˜¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("signals_rule.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # 4. íŠ¸ë ˆì´ë“œ íƒ­
    with tab4:
        st.subheader("ğŸ’° ê±°ë˜ ë‚´ì—­")
        
        trades_path = run_path / "trades.csv"
        if trades_path.exists():
            trades_df = load_csv_file(trades_path)
            if trades_df is not None:
                # ë‚ ì§œ/í‹°ì»¤ í•„í„° ì ìš©
                if 'date' in trades_df.columns:
                    trades_df['date'] = pd.to_datetime(trades_df['date'])
                    mask = (trades_df['date'] >= pd.to_datetime(start_date)) & (trades_df['date'] <= pd.to_datetime(end_date))
                    trades_df = trades_df[mask]
                
                if 'ticker' in trades_df.columns and selected_tickers:
                    trades_df = trades_df[trades_df['ticker'].isin(selected_tickers)]
                
                # KPI ê³„ì‚°
                col1, col2, col3 = st.columns(3)
                with col1:
                    total_pnl = trades_df['pnl'].sum() if 'pnl' in trades_df.columns else 0
                    st.metric("ğŸ’° ëˆ„ì  PnL", f"{total_pnl:,.0f}ì›")
                
                with col2:
                    if 'pnl' in trades_df.columns:
                        win_rate = (trades_df['pnl'] > 0).mean() * 100
                        st.metric("ğŸ¯ ìŠ¹ë¥ ", f"{win_rate:.1f}%")
                    else:
                        st.metric("ğŸ¯ ìŠ¹ë¥ ", "N/A")
                
                with col3:
                    total_trades = len(trades_df)
                    st.metric("ğŸ“Š ì´ ê±°ë˜ìˆ˜", f"{total_trades:,}")
                
                # ê±°ë˜ ë‚´ì—­ í‘œ
                st.dataframe(trades_df, use_container_width=True)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                if st.button("ğŸ”½ ê±°ë˜ ë‚´ì—­ CSV ë‹¤ìš´ë¡œë“œ"):
                    csv_link = get_csv_download_link(trades_df, f"trades_{selected_run}.csv")
                    st.markdown(csv_link, unsafe_allow_html=True)
            else:
                st.error("ê±°ë˜ ë‚´ì—­ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("trades.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # 5. í´ëŸ¬ìŠ¤í„°ë§ íƒ­
    with tab5:
        st.subheader("ğŸ” í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„")
        
        # í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸
        clustering_files = list(run_path.glob("*clustering*"))
        
        if clustering_files:
            st.info("í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ íŒŒì¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            for file in clustering_files:
                st.write(f"ğŸ“ {file.name}")
                
                if file.suffix == '.csv':
                    df = load_csv_file(file)
                    if df is not None:
                        st.dataframe(df.head())
                elif file.suffix == '.json':
                    data = load_json_file(file)
                    if data:
                        st.json(data)
        else:
            st.warning("í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.info("clustering.pyë¥¼ ì‹¤í–‰í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
    
    # 6. ë¦¬í¬íŠ¸ íƒ­
    with tab6:
        st.subheader("ğŸ“„ ë¦¬í¬íŠ¸")
        
        # reports/ ë””ë ‰í† ë¦¬ì—ì„œ ìµœì‹  summary íŒŒì¼ ì°¾ê¸°
        reports_dir = Path("reports")
        summary_files = list(reports_dir.glob("summary_*.md"))
        
        if summary_files:
            # ìµœì‹  íŒŒì¼ ì„ íƒ
            latest_summary = max(summary_files, key=os.path.getctime)
            
            st.subheader(f"ğŸ“„ {latest_summary.name}")
            
            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸° ë° í‘œì‹œ
            try:
                with open(latest_summary, 'r', encoding='utf-8') as f:
                    content = f.read()
                st.markdown(content)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                if st.button("ğŸ”½ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ"):
                    with open(latest_summary, 'r', encoding='utf-8') as f:
                        file_content = f.read()
                    st.download_button(
                        label="ğŸ“„ ë§ˆí¬ë‹¤ìš´ ë‹¤ìš´ë¡œë“œ",
                        data=file_content,
                        file_name=latest_summary.name,
                        mime="text/markdown"
                    )
            except Exception as e:
                st.error(f"ë¦¬í¬íŠ¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
        else:
            st.warning("summary_*.md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ë©´ main.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    main()

