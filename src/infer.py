#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - Inference Module
ëª¨ë¸ ì˜ˆì¸¡ ë° ë§¤ë§¤ ì‹ í˜¸ ìƒì„±

Functions:
- load_trained_model: í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
- predict_probability: í™•ë¥  ì˜ˆì¸¡
- generate_trading_signals: ë§¤ë§¤ ì‹ í˜¸ ìƒì„±
- optimize_threshold: ì„ê³„ê°’ ìµœì í™”
- create_signal_report: ì‹ í˜¸ ë¦¬í¬íŠ¸ ìƒì„±
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Tuple, List, Optional
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# TensorFlow/Keras
try:
    import tensorflow as tf
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from train import load_model, evaluate_model
from dataio import prepare_ml_data

def load_trained_model(model_path: str) -> Dict[str, Any]:
    """
    í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ë¡œë“œëœ ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„°
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“‚ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì¤‘... ({model_path})")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    # ëª¨ë¸ ë¡œë“œ
    model = tf.keras.models.load_model(model_path)
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata_path = model_path.replace('.h5', '_metadata.json')
    metadata = {}
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return {
        'model': model,
        'metadata': metadata
    }

def predict_probability(model, 
                       X: np.ndarray,
                       batch_size: int = 32) -> np.ndarray:
    """
    í™•ë¥  ì˜ˆì¸¡
    
    Args:
        model: í›ˆë ¨ëœ ëª¨ë¸
        X: ì…ë ¥ ë°ì´í„°
        batch_size: ë°°ì¹˜ í¬ê¸°
        
    Returns:
        ì˜ˆì¸¡ í™•ë¥  ë°°ì—´
    """
    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”® í™•ë¥  ì˜ˆì¸¡ ì¤‘...")
    
    # ì˜ˆì¸¡ ì‹¤í–‰
    probabilities = model.predict(X, batch_size=batch_size, verbose=0)
    
    # 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
    if probabilities.ndim > 1:
        probabilities = probabilities.flatten()
    
    print(f"âœ… {len(probabilities)}ê°œ í™•ë¥  ì˜ˆì¸¡ ì™„ë£Œ!")
    return probabilities

def generate_trading_signals(probabilities: np.ndarray,
                           threshold: float = 0.5,
                           min_confidence: float = 0.6,
                           signal_type: str = 'binary') -> Dict[str, Any]:
    """
    ë§¤ë§¤ ì‹ í˜¸ ìƒì„±
    
    Args:
        probabilities: ì˜ˆì¸¡ í™•ë¥ 
        threshold: ë¶„ë¥˜ ì„ê³„ê°’
        min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        signal_type: ì‹ í˜¸ íƒ€ì… ('binary', 'confidence', 'gradient')
        
    Returns:
        ì‹ í˜¸ ë”•ì…”ë„ˆë¦¬
    """
    print(f"ğŸ“Š ë§¤ë§¤ ì‹ í˜¸ ìƒì„± ì¤‘... (ì„ê³„ê°’: {threshold}, ì‹ ë¢°ë„: {min_confidence})")
    
    signals = {}
    
    if signal_type == 'binary':
        # ì´ì§„ ì‹ í˜¸ (0 ë˜ëŠ” 1)
        binary_signals = (probabilities > threshold).astype(int)
        signals['binary'] = binary_signals
        signals['confidence'] = np.abs(probabilities - 0.5) * 2  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
    
    elif signal_type == 'confidence':
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì‹ í˜¸
        confidence = np.abs(probabilities - 0.5) * 2
        binary_signals = (probabilities > threshold).astype(int)
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ì‹ í˜¸ëŠ” ì œê±°
        low_confidence_mask = confidence < min_confidence
        binary_signals[low_confidence_mask] = 0
        
        signals['binary'] = binary_signals
        signals['confidence'] = confidence
        signals['filtered_count'] = np.sum(low_confidence_mask)
    
    elif signal_type == 'gradient':
        # ê·¸ë¼ë””ì–¸íŠ¸ ê¸°ë°˜ ì‹ í˜¸ (í™•ë¥  ë³€í™”ìœ¨)
        if len(probabilities) > 1:
            gradient = np.gradient(probabilities)
            signals['gradient'] = gradient
            signals['binary'] = (gradient > 0).astype(int)  # ìƒìŠ¹ ì¶”ì„¸
        else:
            signals['gradient'] = np.array([0])
            signals['binary'] = np.array([0])
    
    # ì‹ í˜¸ í†µê³„
    signal_counts = np.bincount(signals['binary'])
    signals['stats'] = {
        'total_signals': len(probabilities),
        'buy_signals': signal_counts[1] if len(signal_counts) > 1 else 0,
        'hold_signals': signal_counts[0] if len(signal_counts) > 0 else 0,
        'buy_ratio': signal_counts[1] / len(probabilities) if len(signal_counts) > 1 else 0,
        'avg_confidence': np.mean(signals.get('confidence', [0])),
        'max_confidence': np.max(signals.get('confidence', [0])),
        'min_confidence': np.min(signals.get('confidence', [0]))
    }
    
    print(f"âœ… ì‹ í˜¸ ìƒì„± ì™„ë£Œ!")
    print(f"   - ì´ ì‹ í˜¸: {signals['stats']['total_signals']}ê°œ")
    print(f"   - ë§¤ìˆ˜ ì‹ í˜¸: {signals['stats']['buy_signals']}ê°œ ({signals['stats']['buy_ratio']:.1%})")
    print(f"   - í‰ê·  ì‹ ë¢°ë„: {signals['stats']['avg_confidence']:.3f}")
    
    return signals

def optimize_threshold(y_true: np.ndarray,
                      y_prob: np.ndarray,
                      metric: str = 'f1',
                      thresholds: np.ndarray = None) -> Dict[str, Any]:
    """
    ì„ê³„ê°’ ìµœì í™”
    
    Args:
        y_true: ì‹¤ì œ ë¼ë²¨
        y_prob: ì˜ˆì¸¡ í™•ë¥ 
        metric: ìµœì í™”í•  ì§€í‘œ ('f1', 'precision', 'recall', 'accuracy', 'roc_auc')
        thresholds: í…ŒìŠ¤íŠ¸í•  ì„ê³„ê°’ë“¤
        
    Returns:
        ìµœì í™” ê²°ê³¼
    """
    print(f"ğŸ¯ ì„ê³„ê°’ ìµœì í™” ì¤‘... (ì§€í‘œ: {metric})")
    
    if thresholds is None:
        thresholds = np.arange(0.1, 0.9, 0.05)
    
    best_threshold = 0.5
    best_score = 0
    threshold_scores = []
    
    for threshold in thresholds:
        # ì„ê³„ê°’ìœ¼ë¡œ ì˜ˆì¸¡
        y_pred = (y_prob > threshold).astype(int)
        
        # ì§€í‘œ ê³„ì‚°
        if metric == 'f1':
            from sklearn.metrics import f1_score
            score = f1_score(y_true, y_pred, zero_division=0)
        elif metric == 'precision':
            from sklearn.metrics import precision_score
            score = precision_score(y_true, y_pred, zero_division=0)
        elif metric == 'recall':
            from sklearn.metrics import recall_score
            score = recall_score(y_true, y_pred, zero_division=0)
        elif metric == 'accuracy':
            score = np.mean(y_true == y_pred)
        elif metric == 'roc_auc':
            from sklearn.metrics import roc_auc_score
            try:
                score = roc_auc_score(y_true, y_prob)
            except ValueError:
                score = 0
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§€í‘œ: {metric}")
        
        threshold_scores.append({
            'threshold': threshold,
            'score': score
        })
        
        if score > best_score:
            best_score = score
            best_threshold = threshold
    
    # ìµœì  ì„ê³„ê°’ìœ¼ë¡œ ìµœì¢… í‰ê°€
    y_pred_best = (y_prob > best_threshold).astype(int)
    
    from sklearn.metrics import classification_report, confusion_matrix
    report = classification_report(y_true, y_pred_best, output_dict=True, zero_division=0)
    cm = confusion_matrix(y_true, y_pred_best)
    
    optimization_result = {
        'best_threshold': best_threshold,
        'best_score': best_score,
        'threshold_scores': threshold_scores,
        'final_metrics': {
            'accuracy': np.mean(y_true == y_pred_best),
            'precision': report['1']['precision'] if '1' in report else 0,
            'recall': report['1']['recall'] if '1' in report else 0,
            'f1_score': report['1']['f1-score'] if '1' in report else 0,
            'confusion_matrix': cm.tolist()
        }
    }
    
    print(f"âœ… ì„ê³„ê°’ ìµœì í™” ì™„ë£Œ!")
    print(f"   - ìµœì  ì„ê³„ê°’: {best_threshold:.3f}")
    print(f"   - ìµœê³  {metric} ì ìˆ˜: {best_score:.3f}")
    
    return optimization_result

def create_signal_report(signals: Dict[str, Any],
                        dates: List[str] = None,
                        prices: List[float] = None) -> str:
    """
    ì‹ í˜¸ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        signals: ì‹ í˜¸ ë”•ì…”ë„ˆë¦¬
        dates: ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
        prices: ê°€ê²© ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ë¦¬í¬íŠ¸ ë¬¸ìì—´
    """
    stats = signals['stats']
    
    report = f"""
ğŸ“Š SectorFlow Lite - ë§¤ë§¤ ì‹ í˜¸ ë¦¬í¬íŠ¸
{'='*50}

ğŸ“ˆ ì‹ í˜¸ í†µê³„
- ì´ ì‹ í˜¸ ìˆ˜: {stats['total_signals']}ê°œ
- ë§¤ìˆ˜ ì‹ í˜¸: {stats['buy_signals']}ê°œ ({stats['buy_ratio']:.1%})
- ë³´ìœ  ì‹ í˜¸: {stats['hold_signals']}ê°œ
- í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}
- ìµœëŒ€ ì‹ ë¢°ë„: {stats['max_confidence']:.3f}
- ìµœì†Œ ì‹ ë¢°ë„: {stats['min_confidence']:.3f}

ğŸ“Š ì‹ í˜¸ ë¶„í¬
"""
    
    # ì‹ í˜¸ ë¶„í¬ ì‹œê°í™” (í…ìŠ¤íŠ¸)
    if 'binary' in signals:
        binary_signals = signals['binary']
        signal_changes = np.diff(binary_signals)
        buy_entries = np.where(signal_changes == 1)[0]
        sell_entries = np.where(signal_changes == -1)[0]
        
        report += f"- ë§¤ìˆ˜ ì§„ì…: {len(buy_entries)}íšŒ\n"
        report += f"- ë§¤ë„ ì§„ì…: {len(sell_entries)}íšŒ\n"
    
    # ì‹ ë¢°ë„ ë¶„í¬
    if 'confidence' in signals:
        confidence = signals['confidence']
        high_conf = np.sum(confidence > 0.8)
        med_conf = np.sum((confidence > 0.5) & (confidence <= 0.8))
        low_conf = np.sum(confidence <= 0.5)
        
        report += f"\nğŸ¯ ì‹ ë¢°ë„ ë¶„í¬\n"
        report += f"- ë†’ìŒ (>0.8): {high_conf}ê°œ ({high_conf/len(confidence):.1%})\n"
        report += f"- ì¤‘ê°„ (0.5-0.8): {med_conf}ê°œ ({med_conf/len(confidence):.1%})\n"
        report += f"- ë‚®ìŒ (â‰¤0.5): {low_conf}ê°œ ({low_conf/len(confidence):.1%})\n"
    
    # ìµœê·¼ ì‹ í˜¸ (ë‚ ì§œì™€ ê°€ê²©ì´ ì œê³µëœ ê²½ìš°)
    if dates is not None and prices is not None and 'binary' in signals:
        report += f"\nğŸ“… ìµœê·¼ ì‹ í˜¸ (ìµœê·¼ 10ê°œ)\n"
        recent_signals = list(zip(dates[-10:], prices[-10:], signals['binary'][-10:]))
        
        for date, price, signal in recent_signals:
            signal_text = "ğŸŸ¢ ë§¤ìˆ˜" if signal == 1 else "ğŸ”´ ë³´ìœ "
            report += f"- {date}: {price:,.0f}ì› {signal_text}\n"
    
    report += f"\n{'='*50}\n"
    
    return report

def predict_and_generate_signals(model_path: str,
                                X: np.ndarray,
                                threshold: float = 0.5,
                                min_confidence: float = 0.6,
                                optimize_thresh: bool = False,
                                y_true: np.ndarray = None,
                                run_id: str = None,
                                ticker: str = None) -> Dict[str, Any]:
    """
    ì˜ˆì¸¡ ë° ì‹ í˜¸ ìƒì„± (í†µí•© í•¨ìˆ˜)
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ
        X: ì…ë ¥ ë°ì´í„°
        threshold: ë¶„ë¥˜ ì„ê³„ê°’
        min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        optimize_thresh: ì„ê³„ê°’ ìµœì í™” ì—¬ë¶€
        y_true: ì‹¤ì œ ë¼ë²¨ (ìµœì í™”ìš©)
        
    Returns:
        ì˜ˆì¸¡ ë° ì‹ í˜¸ ê²°ê³¼
    """
    print("ğŸš€ ì˜ˆì¸¡ ë° ì‹ í˜¸ ìƒì„± ì‹œì‘...")
    
    # ëª¨ë¸ ë¡œë“œ
    model_data = load_trained_model(model_path)
    model = model_data['model']
    metadata = model_data['metadata']
    
    # í™•ë¥  ì˜ˆì¸¡
    probabilities = predict_probability(model, X)
    
    # ì„ê³„ê°’ ìµœì í™” (ì‹¤ì œ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš°)
    if optimize_thresh and y_true is not None:
        print("ğŸ¯ ì„ê³„ê°’ ìµœì í™” ì‹¤í–‰...")
        optimization_result = optimize_threshold(y_true, probabilities)
        threshold = optimization_result['best_threshold']
        print(f"   - ìµœì  ì„ê³„ê°’: {threshold:.3f}")
    
    # ì‹ í˜¸ ìƒì„±
    signals = generate_trading_signals(
        probabilities, 
        threshold=threshold, 
        min_confidence=min_confidence
    )
    
    # ê²°ê³¼ í†µí•©
    result = {
        'probabilities': probabilities,
        'signals': signals,
        'threshold': threshold,
        'model_metadata': metadata,
        'optimization_result': optimization_result if optimize_thresh and y_true is not None else None
    }
    
    # ì‹ í˜¸ CSV ì €ì¥
    if run_id and ticker:
        save_signals_csv(probabilities, signals, threshold, run_id, ticker, metadata)
    
    print("âœ… ì˜ˆì¸¡ ë° ì‹ í˜¸ ìƒì„± ì™„ë£Œ!")
    return result

def save_signals_csv(probabilities: np.ndarray,
                    signals: Dict[str, Any],
                    threshold: float,
                    run_id: str,
                    ticker: str,
                    model_metadata: Dict[str, Any]) -> str:
    """ëª¨ë¸ ì‹ í˜¸ë¥¼ CSVë¡œ ì €ì¥"""
    import pandas as pd
    import os
    from datetime import datetime
    
    # runs ë””ë ‰í† ë¦¬ ìƒì„±
    runs_dir = f"runs/{run_id}"
    os.makedirs(runs_dir, exist_ok=True)
    
    # ì‹ í˜¸ ë°ì´í„° ìƒì„±
    dates = pd.date_range(start='2024-01-01', periods=len(probabilities), freq='D')
    
    signals_data = {
        'date': dates,
        'ticker': ticker,
        'prob': probabilities,
        'signal': signals['binary'],
        'model_name': model_metadata.get('model_name', 'unknown'),
        'threshold': threshold
    }
    
    # DataFrame ìƒì„±
    df_signals = pd.DataFrame(signals_data)
    
    # CSV ì €ì¥
    csv_path = os.path.join(runs_dir, "signals_model.csv")
    df_signals.to_csv(csv_path, index=False)
    
    print(f"ğŸ’¾ ëª¨ë¸ ì‹ í˜¸ ì €ì¥: {csv_path}")
    return csv_path

def batch_predict(symbols: List[str],
                  model_paths: Dict[str, str],
                  processed_data: Dict[str, Any],
                  threshold: float = 0.5,
                  min_confidence: float = 0.6) -> Dict[str, Any]:
    """
    ë°°ì¹˜ ì˜ˆì¸¡ (ì—¬ëŸ¬ ì¢…ëª©)
    
    Args:
        symbols: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        model_paths: ì¢…ëª©ë³„ ëª¨ë¸ ê²½ë¡œ
        processed_data: ì²˜ë¦¬ëœ ë°ì´í„°
        threshold: ë¶„ë¥˜ ì„ê³„ê°’
        min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        
    Returns:
        ëª¨ë“  ì¢…ëª©ì˜ ì˜ˆì¸¡ ê²°ê³¼
    """
    print("ğŸš€ ë°°ì¹˜ ì˜ˆì¸¡ ì‹œì‘...")
    
    all_predictions = {}
    
    for symbol in symbols:
        if symbol not in model_paths:
            print(f"   âš ï¸ {symbol}: ëª¨ë¸ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        if symbol not in processed_data:
            print(f"   âš ï¸ {symbol}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        try:
            print(f"   ğŸ“Š {symbol} ì˜ˆì¸¡ ì¤‘...")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            X_test = processed_data[symbol]['X_test']
            y_test = processed_data[symbol]['y_test']
            
            # ì˜ˆì¸¡ ë° ì‹ í˜¸ ìƒì„±
            result = predict_and_generate_signals(
                model_paths[symbol],
                X_test,
                threshold=threshold,
                min_confidence=min_confidence,
                optimize_thresh=True,
                y_true=y_test
            )
            
            all_predictions[symbol] = result
            print(f"   âœ… {symbol} ì˜ˆì¸¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ {symbol} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"âœ… ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ! ({len(all_predictions)}ê°œ ì¢…ëª©)")
    return all_predictions

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SectorFlow Lite - Inference Module í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if not TENSORFLOW_AVAILABLE:
        print("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # ì„¤ì •
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-12-31',
        'lookback': 30,
        'feature_cols': ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'],
        'scale_method': 'standard'
    }
    
    symbols = ['005930', '000660']  # í…ŒìŠ¤íŠ¸ìš© 2ê°œ ì¢…ëª©
    
    # ë°ì´í„° ì¤€ë¹„
    processed_data = prepare_ml_data(symbols, config)
    
    # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„± ë° í›ˆë ¨ (í…ŒìŠ¤íŠ¸ìš©)
    from train import train_all_models
    training_config = {
        'epochs': 10,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì€ ì—í¬í¬
        'batch_size': 32,
        'patience': 5
    }
    
    print("ğŸ”§ í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    training_results = train_all_models(
        processed_data, 
        model_types=['gru'], 
        config=training_config
    )
    
    # ëª¨ë¸ ê²½ë¡œ ìƒì„± (ì‹¤ì œë¡œëŠ” ì €ì¥ëœ ëª¨ë¸ì„ ì‚¬ìš©)
    model_paths = {}
    for symbol in symbols:
        if symbol in training_results:
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œë¥¼ ì‚¬ìš©
            model_paths[symbol] = f"models/{symbol}_gru_model.h5"
    
    # ë°°ì¹˜ ì˜ˆì¸¡
    if model_paths:
        predictions = batch_predict(
            symbols, 
            model_paths, 
            processed_data,
            threshold=0.5,
            min_confidence=0.6
        )
        
        # ê²°ê³¼ ìš”ì•½
        print("\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        for symbol, result in predictions.items():
            signals = result['signals']
            stats = signals['stats']
            print(f"\n{symbol}:")
            print(f"   - ë§¤ìˆ˜ ì‹ í˜¸: {stats['buy_signals']}ê°œ ({stats['buy_ratio']:.1%})")
            print(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}")
            print(f"   - ì‚¬ìš©ëœ ì„ê³„ê°’: {result['threshold']:.3f}")
    
    print("\nâœ… Inference Module í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return predictions if 'predictions' in locals() else None

if __name__ == "__main__":
    results = main()
