#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SectorFlow Lite - Baseline Models Module
ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ë¡œì§€ìŠ¤í‹± íšŒê·€, XGBoost) êµ¬í˜„

Functions:
- train_logistic_regression: ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í›ˆë ¨
- train_xgboost: XGBoost ëª¨ë¸ í›ˆë ¨
- evaluate_model: ëª¨ë¸ í‰ê°€
- compare_models: ëª¨ë¸ ì„±ê³¼ ë¹„êµ
- generate_baseline_report: ë² ì´ìŠ¤ë¼ì¸ ë¦¬í¬íŠ¸ ìƒì„±
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.model_selection import cross_val_score, StratifiedKFold
import warnings
warnings.filterwarnings('ignore')

# XGBoostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-exceptë¡œ ì²˜ë¦¬
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install xgboostë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

def train_logistic_regression(X_train: np.ndarray, 
                             y_train: np.ndarray,
                             X_valid: np.ndarray, 
                             y_valid: np.ndarray,
                             **kwargs) -> Dict[str, Any]:
    """
    ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í›ˆë ¨
    
    Args:
        X_train: í›ˆë ¨ í”¼ì²˜ (3D ë°°ì—´)
        y_train: í›ˆë ¨ ë¼ë²¨
        X_valid: ê²€ì¦ í”¼ì²˜ (3D ë°°ì—´)
        y_valid: ê²€ì¦ ë¼ë²¨
        **kwargs: ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        
    Returns:
        í›ˆë ¨ëœ ëª¨ë¸ê³¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸ”§ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    # 3D ë°°ì—´ì„ 2Dë¡œ ë³€í™˜ (ì‹œê³„ì—´ ë°ì´í„°ë¥¼ í‰ë©´í™”)
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # ëª¨ë¸ ìƒì„±
    model = LogisticRegression(
        random_state=42,
        max_iter=1000,
        **kwargs
    )
    
    # ëª¨ë¸ í›ˆë ¨
    model.fit(X_train_2d, y_train)
    
    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # í‰ê°€
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    results = {
        'model': model,
        'model_name': 'Logistic Regression',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': None,  # ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” íŠ¹ì„± ì¤‘ìš”ë„ê°€ ì œí•œì 
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("âœ… ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return results

def train_xgboost(X_train: np.ndarray, 
                  y_train: np.ndarray,
                  X_valid: np.ndarray, 
                  y_valid: np.ndarray,
                  **kwargs) -> Dict[str, Any]:
    """
    XGBoost ëª¨ë¸ í›ˆë ¨
    
    Args:
        X_train: í›ˆë ¨ í”¼ì²˜ (3D ë°°ì—´)
        y_train: í›ˆë ¨ ë¼ë²¨
        X_valid: ê²€ì¦ í”¼ì²˜ (3D ë°°ì—´)
        y_valid: ê²€ì¦ ë¼ë²¨
        **kwargs: ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        
    Returns:
        í›ˆë ¨ëœ ëª¨ë¸ê³¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not XGBOOST_AVAILABLE:
        raise ImportError("XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install xgboostë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    
    print("ğŸ”§ XGBoost ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    # 3D ë°°ì—´ì„ 2Dë¡œ ë³€í™˜
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    default_params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'random_state': 42,
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8
    }
    
    # ì‚¬ìš©ì íŒŒë¼ë¯¸í„°ë¡œ ì—…ë°ì´íŠ¸
    default_params.update(kwargs)
    
    # ëª¨ë¸ ìƒì„±
    model = xgb.XGBClassifier(**default_params)
    
    # ëª¨ë¸ í›ˆë ¨
    model.fit(
        X_train_2d, y_train,
        eval_set=[(X_valid_2d, y_valid)],
        early_stopping_rounds=10,
        verbose=False
    )
    
    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # í‰ê°€
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = model.feature_importances_
    
    results = {
        'model': model,
        'model_name': 'XGBoost',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': feature_importance,
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("âœ… XGBoost ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return results

def train_random_forest(X_train: np.ndarray, 
                       y_train: np.ndarray,
                       X_valid: np.ndarray, 
                       y_valid: np.ndarray,
                       **kwargs) -> Dict[str, Any]:
    """
    ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨ (XGBoost ëŒ€ì•ˆ)
    
    Args:
        X_train: í›ˆë ¨ í”¼ì²˜ (3D ë°°ì—´)
        y_train: í›ˆë ¨ ë¼ë²¨
        X_valid: ê²€ì¦ í”¼ì²˜ (3D ë°°ì—´)
        y_valid: ê²€ì¦ ë¼ë²¨
        **kwargs: ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        
    Returns:
        í›ˆë ¨ëœ ëª¨ë¸ê³¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸ”§ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    # 3D ë°°ì—´ì„ 2Dë¡œ ë³€í™˜
    X_train_2d = X_train.reshape(X_train.shape[0], -1)
    X_valid_2d = X_valid.reshape(X_valid.shape[0], -1)
    
    # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    default_params = {
        'n_estimators': 100,
        'max_depth': 10,
        'random_state': 42,
        'n_jobs': -1
    }
    
    # ì‚¬ìš©ì íŒŒë¼ë¯¸í„°ë¡œ ì—…ë°ì´íŠ¸
    default_params.update(kwargs)
    
    # ëª¨ë¸ ìƒì„±
    model = RandomForestClassifier(**default_params)
    
    # ëª¨ë¸ í›ˆë ¨
    model.fit(X_train_2d, y_train)
    
    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_2d)
    y_valid_pred = model.predict(X_valid_2d)
    y_train_proba = model.predict_proba(X_train_2d)[:, 1]
    y_valid_proba = model.predict_proba(X_valid_2d)[:, 1]
    
    # í‰ê°€
    train_metrics = evaluate_model(y_train, y_train_pred, y_train_proba, "Train")
    valid_metrics = evaluate_model(y_valid, y_valid_pred, y_valid_proba, "Valid")
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = model.feature_importances_
    
    results = {
        'model': model,
        'model_name': 'Random Forest',
        'train_metrics': train_metrics,
        'valid_metrics': valid_metrics,
        'feature_importance': feature_importance,
        'predictions': {
            'train_pred': y_train_pred,
            'valid_pred': y_valid_pred,
            'train_proba': y_train_proba,
            'valid_proba': y_valid_proba
        }
    }
    
    print("âœ… ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return results

def evaluate_model(y_true: np.ndarray, 
                   y_pred: np.ndarray, 
                   y_proba: np.ndarray, 
                   dataset_name: str) -> Dict[str, Any]:
    """
    ëª¨ë¸ í‰ê°€
    
    Args:
        y_true: ì‹¤ì œ ë¼ë²¨
        y_pred: ì˜ˆì¸¡ ë¼ë²¨
        y_proba: ì˜ˆì¸¡ í™•ë¥ 
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
        
    Returns:
        í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    # ê¸°ë³¸ ì§€í‘œ
    accuracy = np.mean(y_true == y_pred)
    
    # ë¶„ë¥˜ ë¦¬í¬íŠ¸
    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_true, y_pred)
    
    # ROC AUC
    try:
        roc_auc = roc_auc_score(y_true, y_proba)
    except ValueError:
        roc_auc = 0.0
    
    # ì •ë°€ë„, ì¬í˜„ìœ¨, F1
    precision = report['1']['precision'] if '1' in report else 0.0
    recall = report['1']['recall'] if '1' in report else 0.0
    f1 = report['1']['f1-score'] if '1' in report else 0.0
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm.tolist(),
        'classification_report': report
    }
    
    print(f"ğŸ“Š {dataset_name} ì„±ê³¼:")
    print(f"   - ì •í™•ë„: {accuracy:.3f}")
    print(f"   - ì •ë°€ë„: {precision:.3f}")
    print(f"   - ì¬í˜„ìœ¨: {recall:.3f}")
    print(f"   - F1 ì ìˆ˜: {f1:.3f}")
    print(f"   - ROC AUC: {roc_auc:.3f}")
    
    return metrics

def compare_models(model_results: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    ëª¨ë¸ ì„±ê³¼ ë¹„êµ
    
    Args:
        model_results: ëª¨ë¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ë¹„êµ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    """
    comparison_data = []
    
    for result in model_results:
        model_name = result['model_name']
        valid_metrics = result['valid_metrics']
        
        comparison_data.append({
            'Model': model_name,
            'Accuracy': valid_metrics['accuracy'],
            'Precision': valid_metrics['precision'],
            'Recall': valid_metrics['recall'],
            'F1 Score': valid_metrics['f1_score'],
            'ROC AUC': valid_metrics['roc_auc']
        })
    
    df_comparison = pd.DataFrame(comparison_data)
    df_comparison = df_comparison.sort_values('ROC AUC', ascending=False)
    
    return df_comparison

def generate_baseline_report(model_results: List[Dict[str, Any]], 
                           comparison_df: pd.DataFrame) -> str:
    """
    ë² ì´ìŠ¤ë¼ì¸ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        model_results: ëª¨ë¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        comparison_df: ëª¨ë¸ ë¹„êµ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        ë¦¬í¬íŠ¸ ë¬¸ìì—´
    """
    report = f"""
ğŸ“Š SectorFlow Lite - Baseline Models ë¦¬í¬íŠ¸
{'='*60}

ğŸ† ëª¨ë¸ ì„±ê³¼ ë¹„êµ
{comparison_df.to_string(index=False)}

ğŸ“ˆ ìƒì„¸ ì„±ê³¼ ë¶„ì„
"""
    
    for result in model_results:
        model_name = result['model_name']
        train_metrics = result['train_metrics']
        valid_metrics = result['valid_metrics']
        
        report += f"""
{model_name}
{'-'*30}
í›ˆë ¨ ë°ì´í„°:
  - ì •í™•ë„: {train_metrics['accuracy']:.3f}
  - ì •ë°€ë„: {train_metrics['precision']:.3f}
  - ì¬í˜„ìœ¨: {train_metrics['recall']:.3f}
  - F1 ì ìˆ˜: {train_metrics['f1_score']:.3f}
  - ROC AUC: {train_metrics['roc_auc']:.3f}

ê²€ì¦ ë°ì´í„°:
  - ì •í™•ë„: {valid_metrics['accuracy']:.3f}
  - ì •ë°€ë„: {valid_metrics['precision']:.3f}
  - ì¬í˜„ìœ¨: {valid_metrics['recall']:.3f}
  - F1 ì ìˆ˜: {valid_metrics['f1_score']:.3f}
  - ROC AUC: {valid_metrics['roc_auc']:.3f}
"""
    
    # ìµœê³  ì„±ê³¼ ëª¨ë¸
    best_model = comparison_df.iloc[0]
    report += f"""

ğŸ¥‡ ìµœê³  ì„±ê³¼ ëª¨ë¸: {best_model['Model']}
   - ROC AUC: {best_model['ROC AUC']:.3f}
   - F1 Score: {best_model['F1 Score']:.3f}

{'='*60}
"""
    
    return report

def train_all_baselines(processed_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨
    
    Args:
        processed_data: ì²˜ë¦¬ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ëª¨ë“  ëª¨ë¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸš€ ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    all_results = {}
    
    for symbol, data in processed_data.items():
        print(f"\nğŸ“Š {symbol} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        X_train = data['X_train']
        y_train = data['y_train']
        X_valid = data['X_valid']
        y_valid = data['y_valid']
        
        symbol_results = []
        
        # 1. ë¡œì§€ìŠ¤í‹± íšŒê·€
        try:
            lr_result = train_logistic_regression(X_train, y_train, X_valid, y_valid)
            symbol_results.append(lr_result)
        except Exception as e:
            print(f"   âŒ ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‹¤íŒ¨: {e}")
        
        # 2. ëœë¤ í¬ë ˆìŠ¤íŠ¸
        try:
            rf_result = train_random_forest(X_train, y_train, X_valid, y_valid)
            symbol_results.append(rf_result)
        except Exception as e:
            print(f"   âŒ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # 3. XGBoost (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if XGBOOST_AVAILABLE:
            try:
                xgb_result = train_xgboost(X_train, y_train, X_valid, y_valid)
                symbol_results.append(xgb_result)
            except Exception as e:
                print(f"   âŒ XGBoost ì‹¤íŒ¨: {e}")
        
        if symbol_results:
            # ëª¨ë¸ ë¹„êµ
            comparison_df = compare_models(symbol_results)
            
            all_results[symbol] = {
                'models': symbol_results,
                'comparison': comparison_df,
                'best_model': symbol_results[0]  # ROC AUC ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ì²« ë²ˆì§¸
            }
            
            print(f"   âœ… {symbol}: {len(symbol_results)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        else:
            print(f"   âŒ {symbol}: ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
    
    print(f"\nâœ… ì´ {len(all_results)}ê°œ ì¢…ëª© ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return all_results

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ SectorFlow Lite - Baseline Models Module í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # dataio.pyì—ì„œ ë°ì´í„° ë¡œë“œ (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš©)
    from dataio import prepare_ml_data
    
    # ì„¤ì •
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-12-31',
        'lookback': 30,
        'feature_cols': ['close', 'volume', 'trading_value', 'returns', 'ma_5', 'ma_20', 'volatility'],
        'scale_method': 'standard'
    }
    
    symbols = ['005930', '000660']  # í…ŒìŠ¤íŠ¸ìš© 2ê°œ ì¢…ëª©
    
    # ë°ì´í„° ì¤€ë¹„
    processed_data = prepare_ml_data(symbols, config)
    
    # ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨
    all_results = train_all_baselines(processed_data)
    
    # ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„±
    print("\nğŸ“Š ì „ì²´ ëª¨ë¸ ì„±ê³¼ ìš”ì•½:")
    for symbol, results in all_results.items():
        print(f"\n{symbol}:")
        print(results['comparison'].to_string(index=False))
    
    print("\nâœ… Baseline Models Module í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return all_results

if __name__ == "__main__":
    results = main()
